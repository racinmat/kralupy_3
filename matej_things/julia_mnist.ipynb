{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics, Printf, BSON\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, throttle, @epochs\n",
    "using Base.Iterators: repeated, partition\n",
    "using Parameters: @with_kw\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw mutable struct Args\n",
    "    η::Float64 = 3e-4       # learning rate\n",
    "    batchsize::Int = 1024   # batch size\n",
    "    epochs::Int = 10        # number of epochs\n",
    "    device::Function = gpu  # set as gpu, if gpu available\n",
    "end\n",
    "\n",
    "function getdata(args)\n",
    "    # Loading Dataset\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "    # Reshape Data in order to flatten each image into a linear array\n",
    "    xtrain = Flux.flatten(xtrain)\n",
    "    xtest = Flux.flatten(xtest)\n",
    "\n",
    "    # One-hot-encode the labels\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    # Batching\n",
    "    train_data = DataLoader(xtrain, ytrain, batchsize=args.batchsize, shuffle=true)\n",
    "    test_data = DataLoader(xtest, ytest, batchsize=args.batchsize)\n",
    "\n",
    "    return train_data, test_data\n",
    "end\n",
    "\n",
    "build_model(; imgsize=(28,28,1), nclasses=10) =  Chain(Dense(prod(imgsize), 32, relu), Dense(32, nclasses))\n",
    "\n",
    "function loss_all(dataloader, model)\n",
    "    l = 0f0\n",
    "    for (x,y) in dataloader\n",
    "        l += logitcrossentropy(model(x), y)\n",
    "    end\n",
    "    l/length(dataloader)\n",
    "end\n",
    "\n",
    "function accuracy(data_loader, model)\n",
    "    acc = 0\n",
    "    for (x,y) in data_loader\n",
    "        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))*1 / size(x,2)\n",
    "    end\n",
    "    acc/length(data_loader)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "152/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19683"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Args()\n",
    "\n",
    "# Load Data\n",
    "train_data,test_data = getdata(args)\n",
    "\n",
    "# Construct model\n",
    "m = build_model()\n",
    "train_data = args.device.(train_data)\n",
    "test_data = args.device.(test_data)\n",
    "m = args.device(m)\n",
    "loss(x,y) = logitcrossentropy(m(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element CUDA.CuArray{Float32,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][1][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1024 Flux.OneHotMatrix{CUDA.CuArray{Flux.OneHotVector,1}}:\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0  …  0  1  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  1  0  1     0  0  0  1  0  0  1  0  0  0  0  1\n",
       " 0  0  1  0  0  0  0  1  0  0  0  0  0     0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  1  0  0  1  0  0  0  0     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  1  0  1  0     1  0  0  0  1  0  0  1  0  0  0  0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip090\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip090)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip091\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip090)\" d=\"\n",
       "M524.751 1486.45 L1963.95 1486.45 L1963.95 47.2441 L524.751 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip092\">\n",
       "    <rect x=\"524\" y=\"47\" width=\"1440\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  737.967,47.2441 737.967,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1004.49,47.2441 1004.49,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1271,47.2441 1271,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1537.52,47.2441 1537.52,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1804.04,47.2441 1804.04,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1486.45 1963.95,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  737.967,1486.45 737.967,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1004.49,1486.45 1004.49,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1271,1486.45 1271,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1537.52,1486.45 1537.52,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1804.04,1486.45 1804.04,1469.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip090)\" d=\"M 0 0 M728.244 1512.56 L746.601 1512.56 L746.601 1516.5 L732.527 1516.5 L732.527 1524.97 Q733.545 1524.62 734.564 1524.46 Q735.582 1524.27 736.601 1524.27 Q742.388 1524.27 745.767 1527.44 Q749.147 1530.62 749.147 1536.03 Q749.147 1541.61 745.675 1544.71 Q742.203 1547.79 735.883 1547.79 Q733.707 1547.79 731.439 1547.42 Q729.193 1547.05 726.786 1546.31 L726.786 1541.61 Q728.869 1542.74 731.092 1543.3 Q733.314 1543.86 735.791 1543.86 Q739.795 1543.86 742.133 1541.75 Q744.471 1539.64 744.471 1536.03 Q744.471 1532.42 742.133 1530.31 Q739.795 1528.21 735.791 1528.21 Q733.916 1528.21 732.041 1528.62 Q730.189 1529.04 728.244 1529.92 L728.244 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M981.361 1543.18 L989 1543.18 L989 1516.82 L980.69 1518.49 L980.69 1514.23 L988.953 1512.56 L993.629 1512.56 L993.629 1543.18 L1001.27 1543.18 L1001.27 1547.12 L981.361 1547.12 L981.361 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1016.34 1515.64 Q1012.73 1515.64 1010.9 1519.2 Q1009.09 1522.75 1009.09 1529.87 Q1009.09 1536.98 1010.9 1540.55 Q1012.73 1544.09 1016.34 1544.09 Q1019.97 1544.09 1021.78 1540.55 Q1023.61 1536.98 1023.61 1529.87 Q1023.61 1522.75 1021.78 1519.2 Q1019.97 1515.64 1016.34 1515.64 M1016.34 1511.93 Q1022.15 1511.93 1025.2 1516.54 Q1028.28 1521.12 1028.28 1529.87 Q1028.28 1538.6 1025.2 1543.21 Q1022.15 1547.79 1016.34 1547.79 Q1010.53 1547.79 1007.45 1543.21 Q1004.39 1538.6 1004.39 1529.87 Q1004.39 1521.12 1007.45 1516.54 Q1010.53 1511.93 1016.34 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1248.38 1543.18 L1256.02 1543.18 L1256.02 1516.82 L1247.71 1518.49 L1247.71 1514.23 L1255.97 1512.56 L1260.65 1512.56 L1260.65 1543.18 L1268.29 1543.18 L1268.29 1547.12 L1248.38 1547.12 L1248.38 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1273.4 1512.56 L1291.76 1512.56 L1291.76 1516.5 L1277.68 1516.5 L1277.68 1524.97 Q1278.7 1524.62 1279.72 1524.46 Q1280.74 1524.27 1281.76 1524.27 Q1287.54 1524.27 1290.92 1527.44 Q1294.3 1530.62 1294.3 1536.03 Q1294.3 1541.61 1290.83 1544.71 Q1287.36 1547.79 1281.04 1547.79 Q1278.86 1547.79 1276.6 1547.42 Q1274.35 1547.05 1271.94 1546.31 L1271.94 1541.61 Q1274.03 1542.74 1276.25 1543.3 Q1278.47 1543.86 1280.95 1543.86 Q1284.95 1543.86 1287.29 1541.75 Q1289.63 1539.64 1289.63 1536.03 Q1289.63 1532.42 1287.29 1530.31 Q1284.95 1528.21 1280.95 1528.21 Q1279.07 1528.21 1277.2 1528.62 Q1275.35 1529.04 1273.4 1529.92 L1273.4 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1518.67 1543.18 L1534.99 1543.18 L1534.99 1547.12 L1513.05 1547.12 L1513.05 1543.18 Q1515.71 1540.43 1520.29 1535.8 Q1524.9 1531.15 1526.08 1529.81 Q1528.32 1527.28 1529.2 1525.55 Q1530.11 1523.79 1530.11 1522.1 Q1530.11 1519.34 1528.16 1517.61 Q1526.24 1515.87 1523.14 1515.87 Q1520.94 1515.87 1518.48 1516.63 Q1516.05 1517.4 1513.28 1518.95 L1513.28 1514.23 Q1516.1 1513.09 1518.55 1512.51 Q1521.01 1511.93 1523.05 1511.93 Q1528.42 1511.93 1531.61 1514.62 Q1534.8 1517.31 1534.8 1521.8 Q1534.8 1523.93 1533.99 1525.85 Q1533.21 1527.74 1531.1 1530.34 Q1530.52 1531.01 1527.42 1534.23 Q1524.32 1537.42 1518.67 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1550.06 1515.64 Q1546.45 1515.64 1544.62 1519.2 Q1542.81 1522.75 1542.81 1529.87 Q1542.81 1536.98 1544.62 1540.55 Q1546.45 1544.09 1550.06 1544.09 Q1553.69 1544.09 1555.5 1540.55 Q1557.33 1536.98 1557.33 1529.87 Q1557.33 1522.75 1555.5 1519.2 Q1553.69 1515.64 1550.06 1515.64 M1550.06 1511.93 Q1555.87 1511.93 1558.92 1516.54 Q1562 1521.12 1562 1529.87 Q1562 1538.6 1558.92 1543.21 Q1555.87 1547.79 1550.06 1547.79 Q1544.25 1547.79 1541.17 1543.21 Q1538.11 1538.6 1538.11 1529.87 Q1538.11 1521.12 1541.17 1516.54 Q1544.25 1511.93 1550.06 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1785.69 1543.18 L1802.01 1543.18 L1802.01 1547.12 L1780.06 1547.12 L1780.06 1543.18 Q1782.72 1540.43 1787.31 1535.8 Q1791.91 1531.15 1793.09 1529.81 Q1795.34 1527.28 1796.22 1525.55 Q1797.12 1523.79 1797.12 1522.1 Q1797.12 1519.34 1795.18 1517.61 Q1793.26 1515.87 1790.15 1515.87 Q1787.96 1515.87 1785.5 1516.63 Q1783.07 1517.4 1780.29 1518.95 L1780.29 1514.23 Q1783.12 1513.09 1785.57 1512.51 Q1788.02 1511.93 1790.06 1511.93 Q1795.43 1511.93 1798.63 1514.62 Q1801.82 1517.31 1801.82 1521.8 Q1801.82 1523.93 1801.01 1525.85 Q1800.22 1527.74 1798.12 1530.34 Q1797.54 1531.01 1794.44 1534.23 Q1791.34 1537.42 1785.69 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M1807.12 1512.56 L1825.48 1512.56 L1825.48 1516.5 L1811.4 1516.5 L1811.4 1524.97 Q1812.42 1524.62 1813.44 1524.46 Q1814.46 1524.27 1815.48 1524.27 Q1821.27 1524.27 1824.65 1527.44 Q1828.02 1530.62 1828.02 1536.03 Q1828.02 1541.61 1824.55 1544.71 Q1821.08 1547.79 1814.76 1547.79 Q1812.59 1547.79 1810.32 1547.42 Q1808.07 1547.05 1805.66 1546.31 L1805.66 1541.61 Q1807.75 1542.74 1809.97 1543.3 Q1812.19 1543.86 1814.67 1543.86 Q1818.67 1543.86 1821.01 1541.75 Q1823.35 1539.64 1823.35 1536.03 Q1823.35 1532.42 1821.01 1530.31 Q1818.67 1528.21 1814.67 1528.21 Q1812.79 1528.21 1810.92 1528.62 Q1809.07 1529.04 1807.12 1529.92 L1807.12 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,260.459 1963.95,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,526.979 1963.95,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,793.498 1963.95,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1060.02 1963.95,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip092)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1326.54 1963.95,1326.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,47.2441 524.751,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,260.459 542.022,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,526.979 542.022,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,793.498 542.022,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1060.02 542.022,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip090)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1326.54 542.022,1326.54 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip090)\" d=\"M 0 0 M467.848 243.179 L486.205 243.179 L486.205 247.115 L472.131 247.115 L472.131 255.587 Q473.149 255.24 474.168 255.078 Q475.186 254.892 476.205 254.892 Q481.992 254.892 485.372 258.064 Q488.751 261.235 488.751 266.652 Q488.751 272.23 485.279 275.332 Q481.807 278.411 475.487 278.411 Q473.311 278.411 471.043 278.04 Q468.798 277.67 466.39 276.929 L466.39 272.23 Q468.473 273.364 470.696 273.92 Q472.918 274.476 475.395 274.476 Q479.399 274.476 481.737 272.369 Q484.075 270.263 484.075 266.652 Q484.075 263.04 481.737 260.934 Q479.399 258.828 475.395 258.828 Q473.52 258.828 471.645 259.244 Q469.793 259.661 467.848 260.54 L467.848 243.179 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M441.83 540.324 L449.469 540.324 L449.469 513.958 L441.159 515.625 L441.159 511.365 L449.423 509.699 L454.099 509.699 L454.099 540.324 L461.737 540.324 L461.737 544.259 L441.83 544.259 L441.83 540.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M476.807 512.777 Q473.196 512.777 471.367 516.342 Q469.561 519.884 469.561 527.013 Q469.561 534.12 471.367 537.685 Q473.196 541.226 476.807 541.226 Q480.441 541.226 482.247 537.685 Q484.075 534.12 484.075 527.013 Q484.075 519.884 482.247 516.342 Q480.441 512.777 476.807 512.777 M476.807 509.074 Q482.617 509.074 485.672 513.68 Q488.751 518.263 488.751 527.013 Q488.751 535.74 485.672 540.347 Q482.617 544.93 476.807 544.93 Q470.997 544.93 467.918 540.347 Q464.862 535.74 464.862 527.013 Q464.862 518.263 467.918 513.68 Q470.997 509.074 476.807 509.074 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M442.825 806.843 L450.464 806.843 L450.464 780.477 L442.154 782.144 L442.154 777.885 L450.418 776.218 L455.094 776.218 L455.094 806.843 L462.733 806.843 L462.733 810.778 L442.825 810.778 L442.825 806.843 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M467.848 776.218 L486.205 776.218 L486.205 780.153 L472.131 780.153 L472.131 788.625 Q473.149 788.278 474.168 788.116 Q475.186 787.931 476.205 787.931 Q481.992 787.931 485.372 791.102 Q488.751 794.273 488.751 799.69 Q488.751 805.269 485.279 808.371 Q481.807 811.449 475.487 811.449 Q473.311 811.449 471.043 811.079 Q468.798 810.708 466.39 809.968 L466.39 805.269 Q468.473 806.403 470.696 806.958 Q472.918 807.514 475.395 807.514 Q479.399 807.514 481.737 805.408 Q484.075 803.301 484.075 799.69 Q484.075 796.079 481.737 793.972 Q479.399 791.866 475.395 791.866 Q473.52 791.866 471.645 792.283 Q469.793 792.699 467.848 793.579 L467.848 776.218 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M445.418 1073.36 L461.737 1073.36 L461.737 1077.3 L439.793 1077.3 L439.793 1073.36 Q442.455 1070.61 447.038 1065.98 Q451.645 1061.32 452.825 1059.98 Q455.071 1057.46 455.95 1055.72 Q456.853 1053.96 456.853 1052.27 Q456.853 1049.52 454.909 1047.78 Q452.987 1046.05 449.886 1046.05 Q447.687 1046.05 445.233 1046.81 Q442.802 1047.58 440.025 1049.13 L440.025 1044.4 Q442.849 1043.27 445.302 1042.69 Q447.756 1042.11 449.793 1042.11 Q455.163 1042.11 458.358 1044.8 Q461.552 1047.48 461.552 1051.97 Q461.552 1054.1 460.742 1056.02 Q459.955 1057.92 457.849 1060.51 Q457.27 1061.19 454.168 1064.4 Q451.066 1067.6 445.418 1073.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M476.807 1045.82 Q473.196 1045.82 471.367 1049.38 Q469.561 1052.92 469.561 1060.05 Q469.561 1067.16 471.367 1070.72 Q473.196 1074.26 476.807 1074.26 Q480.441 1074.26 482.247 1070.72 Q484.075 1067.16 484.075 1060.05 Q484.075 1052.92 482.247 1049.38 Q480.441 1045.82 476.807 1045.82 M476.807 1042.11 Q482.617 1042.11 485.672 1046.72 Q488.751 1051.3 488.751 1060.05 Q488.751 1068.78 485.672 1073.39 Q482.617 1077.97 476.807 1077.97 Q470.997 1077.97 467.918 1073.39 Q464.862 1068.78 464.862 1060.05 Q464.862 1051.3 467.918 1046.72 Q470.997 1042.11 476.807 1042.11 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M446.413 1339.88 L462.733 1339.88 L462.733 1343.82 L440.788 1343.82 L440.788 1339.88 Q443.45 1337.13 448.034 1332.5 Q452.64 1327.84 453.821 1326.5 Q456.066 1323.98 456.946 1322.24 Q457.849 1320.48 457.849 1318.79 Q457.849 1316.04 455.904 1314.3 Q453.983 1312.57 450.881 1312.57 Q448.682 1312.57 446.228 1313.33 Q443.798 1314.09 441.02 1315.65 L441.02 1310.92 Q443.844 1309.79 446.298 1309.21 Q448.751 1308.63 450.788 1308.63 Q456.159 1308.63 459.353 1311.32 Q462.548 1314 462.548 1318.49 Q462.548 1320.62 461.737 1322.54 Q460.95 1324.44 458.844 1327.03 Q458.265 1327.71 455.163 1330.92 Q452.062 1334.12 446.413 1339.88 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip090)\" d=\"M 0 0 M467.848 1309.26 L486.205 1309.26 L486.205 1313.19 L472.131 1313.19 L472.131 1321.66 Q473.149 1321.32 474.168 1321.15 Q475.186 1320.97 476.205 1320.97 Q481.992 1320.97 485.372 1324.14 Q488.751 1327.31 488.751 1332.73 Q488.751 1338.31 485.279 1341.41 Q481.807 1344.49 475.487 1344.49 Q473.311 1344.49 471.043 1344.12 Q468.798 1343.75 466.39 1343.01 L466.39 1338.31 Q468.473 1339.44 470.696 1340 Q472.918 1340.55 475.395 1340.55 Q479.399 1340.55 481.737 1338.45 Q484.075 1336.34 484.075 1332.73 Q484.075 1329.12 481.737 1327.01 Q479.399 1324.9 475.395 1324.9 Q473.52 1324.9 471.645 1325.32 Q469.793 1325.74 467.848 1326.62 L467.848 1309.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><g clip-path=\"url(#clip092)\">\n",
       "<image width=\"1493\" height=\"1493\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAABdUAAAXVCAYAAADjLzZmAAAgAElEQVR4nOzaMS6tbRiG0U12pRIJ\n",
       "I9CYg2QrJEag0in1RqDRmYICMzAIJY2aCegp/L2c5L9yfNt7sNYI7va58qzMZrP3GQAAAAAA8L9W\n",
       "Rw8AAAAAAIDvQlQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBoPnoAAADwZ2tra6MnLMXd3d3oCZO7vr4ePWEy5+fnoycAAPzTfKoDAAAAAEAkqgMAAAAAQCSq\n",
       "AwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAA\n",
       "QCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "JKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQDQfPQAAAPizvb290ROWYnt7e/SEyd3c3IyeAADAF/GpDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAA\n",
       "AAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAA\n",
       "AACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA0cps\n",
       "NnsfPQIAAD5jdfVn/oo8Pj6OnrAUV1dXoydM7uzsbPQEAAC+yM+8PgAAAAAAYAlEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAA\n",
       "AACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiFZms9n76BEAAPAZR0dHoycsxcXFxegJS7G1tTV6AgAA/DWf6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQzUcPAACAzzo+Ph49YSlu\n",
       "b29HTwAAAD7wqQ4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAA\n",
       "AAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAA\n",
       "AACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA0Xz0AAAAvtbu7u7oCZNbLBajJyzFzs7O\n",
       "6AkAAMAHPtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEA\n",
       "AAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAA\n",
       "AAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAA\n",
       "ACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAA\n",
       "IBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAg\n",
       "EtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAAgEtUBAAAAACCajx4AAMDXOjg4GD1hcs/Pz6MnLMXT09PoCQAAwAc+1QEA\n",
       "AAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAA\n",
       "AAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAA\n",
       "ACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAA\n",
       "IBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAg\n",
       "EtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLV\n",
       "AQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgmo8eAADwHWxubo6eMJmTk5PREyZ3eno6esJSvL6+jp4AAAB8\n",
       "4FMdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAi\n",
       "UR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJR\n",
       "HQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEd\n",
       "AAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0A\n",
       "AAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAA\n",
       "AAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAA\n",
       "AAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAA\n",
       "ACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAAKL56AEAAN/B/v7+6AmT2djYGD1hcvf396MnAAAAv4RP\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAA\n",
       "AACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACI5qMHAAB8B4vFYvSEyby8vIyeMLmHh4fREwAAgF/CpzoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARPPR\n",
       "AwCAn2V9fX30hKU4PDwcPWEyl5eXoydM7u3tbfQEAADgl/CpDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAP+xa/8oQt1rHIdnyEytUXsL/xBUsLSxSCmCugHBRhfh\n",
       "HrKAFBZa2BoVtJkoKmgrKgxYithYWIqgMHcFl/spzvG9mTzPCr4/OJziwwsAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEG1NDwAA9pfDhw9PT1jFoUOHpics5suXL9MTiA4ePDg9YRXXr1+fnrC4/fSm\n",
       "b9++TU9YxV9//TU9YRW3b9+enrCKDx8+TE8AgP/KpToAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARFvT\n",
       "AwCA/eX8+fPTE1axt7c3PWExr169mp6wuGPHjk1PWMXDhw+nJ6zi5MmT0xMW9+eff05PWMzHjx+n\n",
       "J6zi5s2b0xNWcfny5ekJq9iP7/r06dP0BAAW4lIdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAA\n",
       "AAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAA\n",
       "ACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAA\n",
       "IlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAi\n",
       "UR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJR\n",
       "HQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEd\n",
       "AAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0A\n",
       "AAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAAKKt6QEA\n",
       "wP5y6dKl6Qmr+Pr16/SExbx//356wuJ2dnamJ6ziwIED0xNWcfbs2ekJi9vd3Z2ewP/w6NGj6Qmr\n",
       "ePfu3fSEVdy9e3d6wuIuXLgwPWEV3759m54A8NO5VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgGhregAAwD/B58+f\n",
       "pycs5saNG9MTFvfbb79NT1jFuXPnpiesYnd3d3oC/0L79bv7/fffpyes4uHDh9MTFnf16tXpCau4\n",
       "devW9ASAn86lOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEW9MDAID95eXLl9MTVnHp0qXpCYu5du3a9ITFvXr1anrCKl6/fj09AfaNvb296Qmr\n",
       "ePHixfSEVfz999/TExb3yy+/TE8AYCEu1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLV\n",
       "AQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEA\n",
       "AAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAEnRHpEAABK0SURBVAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLV\n",
       "AQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEA\n",
       "AAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAA\n",
       "AAAg2poeAADsL8+fP5+esIrt7e3pCYs5evTo9ITFPXjwYHrCKn78+DE9AWDE8ePHpycsbmdnZ3oC\n",
       "AAtxqQ4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAA\n",
       "AAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA0db0AABgf3n9+vX0hFU8fvx4esJiLl68OD1hcSdO\n",
       "nJiesIrt7e3pCav4/v379AT+hfbrf+KPP/6YnrCKI0eOTE9Y3L1796YnALAQl+oAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEG1ubGzsTY8AAPh/d+zYsekJi7l///70hMWdPn16esIqnjx5Mj1hFW/evJme\n",
       "sLjDhw9PT1jMmTNnpies4uzZs9MTVvHhw4fpCau4cuXK9ITF7e7uTk8AYCEu1QEAAAAAIBLVAQAA\n",
       "AAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAA\n",
       "ACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAA\n",
       "IBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAg\n",
       "EtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLV\n",
       "AQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEA\n",
       "AAAAINrc2NjYmx4BAMDPc+rUqekJi3v69On0hFX8+uuv0xNW8ezZs+kJi9vc3JyesJi3b99OT1jF\n",
       "u3fvpies4s6dO9MTAOBfx6U6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESbGxsbe9MjAAAAAADgn8Cl\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA/KcdOxAAAAAAEORvvcIAhREAAADAJNUBAAAAAGCS\n",
       "6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUB\n",
       "AAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAA\n",
       "AADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAA\n",
       "gEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACT\n",
       "VAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkO\n",
       "AAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAA\n",
       "AAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAA\n",
       "AExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACY\n",
       "pDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1\n",
       "AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAA\n",
       "AAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAA\n",
       "AGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADA\n",
       "JNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmq\n",
       "AwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcA\n",
       "AAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAA\n",
       "AACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExSHQAAAAAA\n",
       "JqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoAAAAAAExS\n",
       "HQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAAAACYpDoA\n",
       "AAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAAMEl1AAAA\n",
       "AACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAACTVAcAAAAAgEmqAwAAAADAJNUBAAAAAGCS6gAAAAAA\n",
       "MEl1AAAAAACYpDoAAAAAAExSHQAAAAAAJqkOAAAAAABTWpvP5fkil2wAAAAASUVORK5CYII=\n",
       "\" transform=\"translate(498, 21)\"/>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Gray.(reshape(train_data[1][1][:,1], (28, 28))'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(softmax(m(train_data[1][1][:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.0003, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training\n",
    "evalcb = () -> @show(loss_all(train_data, m))\n",
    "opt = ADAM(args.η)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 2.3534393f0\n",
      "loss_all(train_data, m) = 2.33233f0\n",
      "loss_all(train_data, m) = 2.311852f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 2.2918763f0\n",
      "loss_all(train_data, m) = 2.2723298f0\n",
      "loss_all(train_data, m) = 2.253152f0\n",
      "loss_all(train_data, m) = 2.2343214f0\n",
      "loss_all(train_data, m) = 2.2158368f0\n",
      "loss_all(train_data, m) = 2.197687f0\n",
      "loss_all(train_data, m) = 2.1797366f0\n",
      "loss_all(train_data, m) = 2.1619365f0\n",
      "loss_all(train_data, m) = 2.1443284f0\n",
      "loss_all(train_data, m) = 2.126797f0\n",
      "loss_all(train_data, m) = 2.1093059f0\n",
      "loss_all(train_data, m) = 2.0918574f0\n",
      "loss_all(train_data, m) = 2.0744774f0\n",
      "loss_all(train_data, m) = 2.0571132f0\n",
      "loss_all(train_data, m) = 2.0397215f0\n",
      "loss_all(train_data, m) = 2.0223613f0\n",
      "loss_all(train_data, m) = 2.0049448f0\n",
      "loss_all(train_data, m) = 1.98755f0\n",
      "loss_all(train_data, m) = 1.9701319f0\n",
      "loss_all(train_data, m) = 1.9527042f0\n",
      "loss_all(train_data, m) = 1.935273f0\n",
      "loss_all(train_data, m) = 1.9178132f0\n",
      "loss_all(train_data, m) = 1.9003494f0\n",
      "loss_all(train_data, m) = 1.8828906f0\n",
      "loss_all(train_data, m) = 1.8654956f0\n",
      "loss_all(train_data, m) = 1.8481374f0\n",
      "loss_all(train_data, m) = 1.8308847f0\n",
      "loss_all(train_data, m) = 1.8136883f0\n",
      "loss_all(train_data, m) = 1.7965505f0\n",
      "loss_all(train_data, m) = 1.7794963f0\n",
      "loss_all(train_data, m) = 1.7625067f0\n",
      "loss_all(train_data, m) = 1.7456377f0\n",
      "loss_all(train_data, m) = 1.7288547f0\n",
      "loss_all(train_data, m) = 1.7121634f0\n",
      "loss_all(train_data, m) = 1.6956043f0\n",
      "loss_all(train_data, m) = 1.6791558f0\n",
      "loss_all(train_data, m) = 1.6628125f0\n",
      "loss_all(train_data, m) = 1.646598f0\n",
      "loss_all(train_data, m) = 1.6305059f0\n",
      "loss_all(train_data, m) = 1.6145304f0\n",
      "loss_all(train_data, m) = 1.5986298f0\n",
      "loss_all(train_data, m) = 1.5827792f0\n",
      "loss_all(train_data, m) = 1.5670174f0\n",
      "loss_all(train_data, m) = 1.5513341f0\n",
      "loss_all(train_data, m) = 1.5357394f0\n",
      "loss_all(train_data, m) = 1.5202298f0\n",
      "loss_all(train_data, m) = 1.5047835f0\n",
      "loss_all(train_data, m) = 1.4894235f0\n",
      "loss_all(train_data, m) = 1.4741349f0\n",
      "loss_all(train_data, m) = 1.4589262f0\n",
      "loss_all(train_data, m) = 1.4437547f0\n",
      "loss_all(train_data, m) = 1.4286865f0\n",
      "loss_all(train_data, m) = 1.413717f0\n",
      "loss_all(train_data, m) = 1.3988726f0\n",
      "loss_all(train_data, m) = 1.3841627f0\n",
      "loss_all(train_data, m) = 1.3696493f0\n",
      "loss_all(train_data, m) = 1.3553407f0\n",
      "loss_all(train_data, m) = 1.3411676f0\n",
      "loss_all(train_data, m) = 1.3271357f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_all(train_data, m) = 1.3132577f0\n",
      "loss_all(train_data, m) = 1.2995521f0\n",
      "loss_all(train_data, m) = 1.2860391f0\n",
      "loss_all(train_data, m) = 1.2727554f0\n",
      "loss_all(train_data, m) = 1.2596326f0\n",
      "loss_all(train_data, m) = 1.2467123f0\n",
      "loss_all(train_data, m) = 1.2340101f0\n",
      "loss_all(train_data, m) = 1.2214692f0\n",
      "loss_all(train_data, m) = 1.2091569f0\n",
      "loss_all(train_data, m) = 1.1970707f0\n",
      "loss_all(train_data, m) = 1.1851658f0\n",
      "loss_all(train_data, m) = 1.1734552f0\n",
      "loss_all(train_data, m) = 1.1619617f0\n",
      "loss_all(train_data, m) = 1.1506397f0\n",
      "loss_all(train_data, m) = 1.1395242f0\n",
      "loss_all(train_data, m) = 1.1286485f0\n",
      "loss_all(train_data, m) = 1.1179984f0\n",
      "loss_all(train_data, m) = 1.1075038f0\n",
      "loss_all(train_data, m) = 1.0971745f0\n",
      "loss_all(train_data, m) = 1.086995f0\n",
      "loss_all(train_data, m) = 1.076983f0\n",
      "loss_all(train_data, m) = 1.0671269f0\n",
      "loss_all(train_data, m) = 1.0573685f0\n",
      "loss_all(train_data, m) = 1.047771f0\n",
      "loss_all(train_data, m) = 1.0383588f0\n",
      "loss_all(train_data, m) = 1.0291572f0\n",
      "loss_all(train_data, m) = 1.0201077f0\n",
      "loss_all(train_data, m) = 1.0111933f0\n",
      "loss_all(train_data, m) = 1.002428f0\n",
      "loss_all(train_data, m) = 0.99383706f0\n",
      "loss_all(train_data, m) = 0.9854225f0\n",
      "loss_all(train_data, m) = 0.9771689f0\n",
      "loss_all(train_data, m) = 0.96907836f0\n",
      "loss_all(train_data, m) = 0.961136f0\n",
      "loss_all(train_data, m) = 0.9533392f0\n",
      "loss_all(train_data, m) = 0.94568413f0\n",
      "loss_all(train_data, m) = 0.9381549f0\n",
      "loss_all(train_data, m) = 0.9307357f0\n",
      "loss_all(train_data, m) = 0.9234476f0\n",
      "loss_all(train_data, m) = 0.9162911f0\n",
      "loss_all(train_data, m) = 0.909249f0\n",
      "loss_all(train_data, m) = 0.9023293f0\n",
      "loss_all(train_data, m) = 0.89553493f0\n",
      "loss_all(train_data, m) = 0.88884526f0\n",
      "loss_all(train_data, m) = 0.88223594f0\n",
      "loss_all(train_data, m) = 0.8757391f0\n",
      "loss_all(train_data, m) = 0.8693522f0\n",
      "loss_all(train_data, m) = 0.8630948f0\n",
      "loss_all(train_data, m) = 0.8569513f0\n",
      "loss_all(train_data, m) = 0.8509107f0\n",
      "loss_all(train_data, m) = 0.8449687f0\n",
      "loss_all(train_data, m) = 0.83915013f0\n",
      "loss_all(train_data, m) = 0.8334139f0\n",
      "loss_all(train_data, m) = 0.82777464f0\n",
      "loss_all(train_data, m) = 0.8222006f0\n",
      "loss_all(train_data, m) = 0.8167073f0\n",
      "loss_all(train_data, m) = 0.8113603f0\n",
      "loss_all(train_data, m) = 0.8061137f0\n",
      "loss_all(train_data, m) = "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8009356f0\n",
      "loss_all(train_data, m) = 0.7958158f0\n",
      "loss_all(train_data, m) = 0.7907799f0\n",
      "loss_all(train_data, m) = 0.78582895f0\n",
      "loss_all(train_data, m) = 0.78098035f0\n",
      "loss_all(train_data, m) = 0.7761857f0\n",
      "loss_all(train_data, m) = 0.77146155f0\n",
      "loss_all(train_data, m) = 0.7668231f0\n",
      "loss_all(train_data, m) = 0.7622621f0\n",
      "loss_all(train_data, m) = 0.75779235f0\n",
      "loss_all(train_data, m) = 0.75339454f0\n",
      "loss_all(train_data, m) = 0.7490568f0\n",
      "loss_all(train_data, m) = 0.7447935f0\n",
      "loss_all(train_data, m) = 0.74059796f0\n",
      "loss_all(train_data, m) = 0.7364681f0\n",
      "loss_all(train_data, m) = 0.73239285f0\n",
      "loss_all(train_data, m) = 0.72838014f0\n",
      "loss_all(train_data, m) = 0.7244573f0\n",
      "loss_all(train_data, m) = 0.72060186f0\n",
      "loss_all(train_data, m) = 0.71680087f0\n",
      "loss_all(train_data, m) = 0.71304184f0\n",
      "loss_all(train_data, m) = 0.7093369f0\n",
      "loss_all(train_data, m) = 0.705679f0\n",
      "loss_all(train_data, m) = 0.7020449f0\n",
      "loss_all(train_data, m) = 0.6984578f0\n",
      "loss_all(train_data, m) = 0.69493455f0\n",
      "loss_all(train_data, m) = 0.6914761f0\n",
      "loss_all(train_data, m) = 0.68804336f0\n",
      "loss_all(train_data, m) = 0.6846162f0\n",
      "loss_all(train_data, m) = 0.6811988f0\n",
      "loss_all(train_data, m) = 0.67782915f0\n",
      "loss_all(train_data, m) = 0.67452264f0\n",
      "loss_all(train_data, m) = 0.6712851f0\n",
      "loss_all(train_data, m) = 0.668097f0\n",
      "loss_all(train_data, m) = 0.66496897f0\n",
      "loss_all(train_data, m) = 0.66190577f0\n",
      "loss_all(train_data, m) = 0.65889305f0\n",
      "loss_all(train_data, m) = 0.6559085f0\n",
      "loss_all(train_data, m) = 0.652941f0\n",
      "loss_all(train_data, m) = 0.6500145f0\n",
      "loss_all(train_data, m) = 0.64712197f0\n",
      "loss_all(train_data, m) = 0.64424527f0\n",
      "loss_all(train_data, m) = 0.6414167f0\n",
      "loss_all(train_data, m) = 0.6386111f0\n",
      "loss_all(train_data, m) = 0.63581175f0\n",
      "loss_all(train_data, m) = 0.6330149f0\n",
      "loss_all(train_data, m) = 0.6302493f0\n",
      "loss_all(train_data, m) = 0.6275262f0\n",
      "loss_all(train_data, m) = 0.62484866f0\n",
      "loss_all(train_data, m) = 0.6222123f0\n",
      "loss_all(train_data, m) = 0.6196167f0\n",
      "loss_all(train_data, m) = 0.61705345f0\n",
      "loss_all(train_data, m) = 0.6145434f0\n",
      "loss_all(train_data, m) = 0.6120593f0\n",
      "loss_all(train_data, m) = 0.6095995f0\n",
      "loss_all(train_data, m) = 0.60715526f0\n",
      "loss_all(train_data, m) = 0.6047298f0\n",
      "loss_all(train_data, m) = 0.6023863f0\n",
      "loss_all(train_data, m) = 0.6000958f0\n",
      "loss_all(train_data, m) = 0.5977904f0\n",
      "loss_all(train_data, m) = 0.59546936f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_all(train_data, m) = 0.5931529f0\n",
      "loss_all(train_data, m) = 0.59085864f0\n",
      "loss_all(train_data, m) = 0.58860177f0\n",
      "loss_all(train_data, m) = 0.5863525f0\n",
      "loss_all(train_data, m) = 0.5841315f0\n",
      "loss_all(train_data, m) = 0.58195174f0\n",
      "loss_all(train_data, m) = 0.5798066f0\n",
      "loss_all(train_data, m) = 0.5777191f0\n",
      "loss_all(train_data, m) = 0.57565427f0\n",
      "loss_all(train_data, m) = 0.5736128f0\n",
      "loss_all(train_data, m) = 0.57159305f0\n",
      "loss_all(train_data, m) = 0.5696021f0\n",
      "loss_all(train_data, m) = 0.56763947f0\n",
      "loss_all(train_data, m) = 0.56568027f0\n",
      "loss_all(train_data, m) = 0.5637178f0\n",
      "loss_all(train_data, m) = 0.56180084f0\n",
      "loss_all(train_data, m) = 0.55991507f0\n",
      "loss_all(train_data, m) = 0.5580545f0\n",
      "loss_all(train_data, m) = 0.5562108f0\n",
      "loss_all(train_data, m) = 0.55438757f0\n",
      "loss_all(train_data, m) = 0.5525823f0\n",
      "loss_all(train_data, m) = 0.5508011f0\n",
      "loss_all(train_data, m) = 0.5490407f0\n",
      "loss_all(train_data, m) = 0.5473154f0\n",
      "loss_all(train_data, m) = 0.54561543f0\n",
      "loss_all(train_data, m) = 0.5439147f0\n",
      "loss_all(train_data, m) = 0.54218125f0\n",
      "loss_all(train_data, m) = 0.5404219f0\n",
      "loss_all(train_data, m) = 0.5386701f0\n",
      "loss_all(train_data, m) = 0.53695047f0\n",
      "loss_all(train_data, m) = 0.53526515f0\n",
      "loss_all(train_data, m) = 0.5335969f0\n",
      "loss_all(train_data, m) = 0.53197706f0\n",
      "loss_all(train_data, m) = 0.5304f0\n",
      "loss_all(train_data, m) = 0.5288587f0\n",
      "loss_all(train_data, m) = 0.52733094f0\n",
      "loss_all(train_data, m) = 0.5257936f0\n",
      "loss_all(train_data, m) = 0.5242733f0\n",
      "loss_all(train_data, m) = 0.5227669f0\n",
      "loss_all(train_data, m) = 0.52125233f0\n",
      "loss_all(train_data, m) = 0.51975983f0\n",
      "loss_all(train_data, m) = 0.51825744f0\n",
      "loss_all(train_data, m) = 0.5167412f0\n",
      "loss_all(train_data, m) = 0.51521724f0\n",
      "loss_all(train_data, m) = 0.51370823f0\n",
      "loss_all(train_data, m) = 0.51223075f0\n",
      "loss_all(train_data, m) = 0.5107799f0\n",
      "loss_all(train_data, m) = 0.509352f0\n",
      "loss_all(train_data, m) = 0.50794894f0\n",
      "loss_all(train_data, m) = 0.50655913f0\n",
      "loss_all(train_data, m) = 0.50519985f0\n",
      "loss_all(train_data, m) = 0.5038527f0\n",
      "loss_all(train_data, m) = 0.50249934f0\n",
      "loss_all(train_data, m) = 0.5011519f0\n",
      "loss_all(train_data, m) = 0.49981287f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.49853855f0\n",
      "loss_all(train_data, m) = 0.49731052f0\n",
      "loss_all(train_data, m) = 0.49604863f0\n",
      "loss_all(train_data, m) = 0.49476096f0\n",
      "loss_all(train_data, m) = 0.49345604f0\n",
      "loss_all(train_data, m) = 0.49216035f0\n",
      "loss_all(train_data, m) = 0.4908761f0\n",
      "loss_all(train_data, m) = 0.48959175f0\n",
      "loss_all(train_data, m) = 0.48833087f0\n",
      "loss_all(train_data, m) = 0.48709065f0\n",
      "loss_all(train_data, m) = 0.4858665f0\n",
      "loss_all(train_data, m) = 0.4846903f0\n",
      "loss_all(train_data, m) = 0.4835205f0\n",
      "loss_all(train_data, m) = 0.48236543f0\n",
      "loss_all(train_data, m) = 0.48121592f0\n",
      "loss_all(train_data, m) = 0.4800877f0\n",
      "loss_all(train_data, m) = 0.47898334f0\n",
      "loss_all(train_data, m) = 0.47786835f0\n",
      "loss_all(train_data, m) = 0.47672296f0\n",
      "loss_all(train_data, m) = 0.47560152f0\n",
      "loss_all(train_data, m) = 0.4745037f0\n",
      "loss_all(train_data, m) = 0.47342408f0\n",
      "loss_all(train_data, m) = 0.4723551f0\n",
      "loss_all(train_data, m) = 0.47129583f0\n",
      "loss_all(train_data, m) = 0.47024992f0\n",
      "loss_all(train_data, m) = 0.46922982f0\n",
      "loss_all(train_data, m) = 0.4682248f0\n",
      "loss_all(train_data, m) = 0.46724215f0\n",
      "loss_all(train_data, m) = 0.46626666f0\n",
      "loss_all(train_data, m) = 0.46528012f0\n",
      "loss_all(train_data, m) = 0.4642484f0\n",
      "loss_all(train_data, m) = 0.46317673f0\n",
      "loss_all(train_data, m) = 0.46210018f0\n",
      "loss_all(train_data, m) = 0.46104866f0\n",
      "loss_all(train_data, m) = 0.4600136f0\n",
      "loss_all(train_data, m) = 0.45899037f0\n",
      "loss_all(train_data, m) = 0.45801887f0\n",
      "loss_all(train_data, m) = 0.45708743f0\n",
      "loss_all(train_data, m) = 0.45618084f0\n",
      "loss_all(train_data, m) = 0.45528007f0\n",
      "loss_all(train_data, m) = 0.45436165f0\n",
      "loss_all(train_data, m) = 0.45345247f0\n",
      "loss_all(train_data, m) = 0.45255113f0\n",
      "loss_all(train_data, m) = 0.45163414f0\n",
      "loss_all(train_data, m) = 0.45072648f0\n",
      "loss_all(train_data, m) = 0.44979742f0\n",
      "loss_all(train_data, m) = 0.44884554f0\n",
      "loss_all(train_data, m) = 0.44788516f0\n",
      "loss_all(train_data, m) = 0.44693387f0\n",
      "loss_all(train_data, m) = 0.44600743f0\n",
      "loss_all(train_data, m) = 0.44510177f0\n",
      "loss_all(train_data, m) = 0.4442112f0\n",
      "loss_all(train_data, m) = 0.44334295f0\n",
      "loss_all(train_data, m) = 0.44247967f0\n",
      "loss_all(train_data, m) = 0.44163588f0\n",
      "loss_all(train_data, m) = 0.44079924f0\n",
      "loss_all(train_data, m) = 0.43994188f0\n",
      "loss_all(train_data, m) = 0.4390907f0\n",
      "loss_all(train_data, m) = 0.4382454f0\n",
      "loss_all(train_data, m) = 0.43745783f0\n",
      "loss_all(train_data, m) = 0.43671167f0\n",
      "loss_all(train_data, m) = 0.43592423f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_all(train_data, m) = 0.43511206f0\n",
      "loss_all(train_data, m) = 0.43427226f0\n",
      "loss_all(train_data, m) = 0.4334367f0\n",
      "loss_all(train_data, m) = 0.43260458f0\n",
      "loss_all(train_data, m) = 0.4317697f0\n",
      "loss_all(train_data, m) = 0.43095407f0\n",
      "loss_all(train_data, m) = 0.43015197f0\n",
      "loss_all(train_data, m) = 0.42935452f0\n",
      "loss_all(train_data, m) = 0.42860496f0\n",
      "loss_all(train_data, m) = 0.42785507f0\n",
      "loss_all(train_data, m) = 0.42711678f0\n",
      "loss_all(train_data, m) = 0.42637646f0\n",
      "loss_all(train_data, m) = 0.42565337f0\n",
      "loss_all(train_data, m) = 0.424952f0\n",
      "loss_all(train_data, m) = 0.42423072f0\n",
      "loss_all(train_data, m) = 0.42346492f0\n",
      "loss_all(train_data, m) = 0.42271355f0\n",
      "loss_all(train_data, m) = 0.42198285f0\n",
      "loss_all(train_data, m) = 0.42126763f0\n",
      "loss_all(train_data, m) = 0.4205607f0\n",
      "loss_all(train_data, m) = 0.41986144f0\n",
      "loss_all(train_data, m) = 0.41917372f0\n",
      "loss_all(train_data, m) = 0.4185153f0\n",
      "loss_all(train_data, m) = 0.41786897f0\n",
      "loss_all(train_data, m) = 0.4172403f0\n",
      "loss_all(train_data, m) = 0.41661075f0\n",
      "loss_all(train_data, m) = 0.41596735f0\n",
      "loss_all(train_data, m) = 0.41527557f0\n",
      "loss_all(train_data, m) = 0.41454256f0\n",
      "loss_all(train_data, m) = 0.4138025f0\n",
      "loss_all(train_data, m) = 0.41308406f0\n",
      "loss_all(train_data, m) = 0.41237435f0\n",
      "loss_all(train_data, m) = 0.41167352f0\n",
      "loss_all(train_data, m) = 0.41102692f0\n",
      "loss_all(train_data, m) = 0.41041625f0\n",
      "loss_all(train_data, m) = 0.4098258f0\n",
      "loss_all(train_data, m) = 0.4092363f0\n",
      "loss_all(train_data, m) = 0.40862387f0\n",
      "loss_all(train_data, m) = 0.40801823f0\n",
      "loss_all(train_data, m) = 0.4074201f0\n",
      "loss_all(train_data, m) = 0.4068051f0\n",
      "loss_all(train_data, m) = 0.40619218f0\n",
      "loss_all(train_data, m) = 0.40555295f0\n",
      "loss_all(train_data, m) = 0.40488777f0\n",
      "loss_all(train_data, m) = 0.40421432f0\n",
      "loss_all(train_data, m) = 0.40355027f0\n",
      "loss_all(train_data, m) = 0.40290707f0\n",
      "loss_all(train_data, m) = 0.4022825f0\n",
      "loss_all(train_data, m) = 0.4016711f0\n",
      "loss_all(train_data, m) = 0.40108055f0\n",
      "loss_all(train_data, m) = 0.4004872f0\n",
      "loss_all(train_data, m) = 0.3999066f0\n",
      "loss_all(train_data, m) = 0.39932987f0\n",
      "loss_all(train_data, m) = 0.39872652f0\n",
      "loss_all(train_data, m) = 0.39813325f0\n",
      "loss_all(train_data, m) = 0.3975479f0\n",
      "loss_all(train_data, m) = 0.39701498f0\n",
      "loss_all(train_data, m) = 0.39652276f0\n",
      "loss_all(train_data, m) = 0.3959868f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.3954254f0\n",
      "loss_all(train_data, m) = 0.3948295f0\n",
      "loss_all(train_data, m) = 0.39423594f0\n",
      "loss_all(train_data, m) = 0.39364436f0\n",
      "loss_all(train_data, m) = 0.39305085f0\n",
      "loss_all(train_data, m) = 0.39247462f0\n",
      "loss_all(train_data, m) = 0.39190868f0\n",
      "loss_all(train_data, m) = 0.39134127f0\n",
      "loss_all(train_data, m) = 0.39082307f0\n",
      "loss_all(train_data, m) = 0.39030117f0\n",
      "loss_all(train_data, m) = 0.38978887f0\n",
      "loss_all(train_data, m) = 0.389271f0\n",
      "loss_all(train_data, m) = 0.38876796f0\n",
      "loss_all(train_data, m) = 0.38828722f0\n",
      "loss_all(train_data, m) = 0.38778093f0\n",
      "loss_all(train_data, m) = 0.3872213f0\n",
      "loss_all(train_data, m) = 0.38667133f0\n",
      "loss_all(train_data, m) = 0.38614073f0\n",
      "loss_all(train_data, m) = 0.3856246f0\n",
      "loss_all(train_data, m) = 0.38511482f0\n",
      "loss_all(train_data, m) = 0.3846124f0\n",
      "loss_all(train_data, m) = 0.38411984f0\n",
      "loss_all(train_data, m) = 0.38366044f0\n",
      "loss_all(train_data, m) = 0.38321164f0\n",
      "loss_all(train_data, m) = 0.38277817f0\n",
      "loss_all(train_data, m) = 0.38233903f0\n",
      "loss_all(train_data, m) = 0.38188478f0\n",
      "loss_all(train_data, m) = 0.38138235f0\n",
      "loss_all(train_data, m) = 0.3808396f0\n",
      "loss_all(train_data, m) = 0.3802905f0\n",
      "loss_all(train_data, m) = 0.37976432f0\n",
      "loss_all(train_data, m) = 0.37924463f0\n",
      "loss_all(train_data, m) = 0.37873214f0\n",
      "loss_all(train_data, m) = 0.37827572f0\n",
      "loss_all(train_data, m) = 0.37784946f0\n",
      "loss_all(train_data, m) = 0.3774382f0\n",
      "loss_all(train_data, m) = 0.37702385f0\n",
      "loss_all(train_data, m) = 0.37658235f0\n",
      "loss_all(train_data, m) = 0.37614635f0\n",
      "loss_all(train_data, m) = 0.37572035f0\n",
      "loss_all(train_data, m) = 0.3752795f0\n",
      "loss_all(train_data, m) = 0.37483606f0\n",
      "loss_all(train_data, m) = 0.37436387f0\n",
      "loss_all(train_data, m) = 0.37386376f0\n",
      "loss_all(train_data, m) = 0.37335494f0\n",
      "loss_all(train_data, m) = 0.37285638f0\n",
      "loss_all(train_data, m) = 0.37237707f0\n",
      "loss_all(train_data, m) = 0.37191468f0\n",
      "loss_all(train_data, m) = 0.37146366f0\n",
      "loss_all(train_data, m) = 0.3710336f0\n",
      "loss_all(train_data, m) = 0.3705949f0\n",
      "loss_all(train_data, m) = 0.37016466f0\n",
      "loss_all(train_data, m) = 0.36973894f0\n",
      "loss_all(train_data, m) = 0.36928633f0\n",
      "loss_all(train_data, m) = 0.3688454f0\n",
      "loss_all(train_data, m) = 0.36841464f0\n",
      "loss_all(train_data, m) = 0.36803266f0\n",
      "loss_all(train_data, m) = 0.36768973f0\n",
      "loss_all(train_data, m) = 0.36730057f0\n",
      "loss_all(train_data, m) = 0.3668874f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.3664349f0\n",
      "loss_all(train_data, m) = 0.36598304f0\n",
      "loss_all(train_data, m) = 0.3655332f0\n",
      "loss_all(train_data, m) = 0.3650815f0\n",
      "loss_all(train_data, m) = 0.364645f0\n",
      "loss_all(train_data, m) = 0.36421937f0\n",
      "loss_all(train_data, m) = 0.36378822f0\n",
      "loss_all(train_data, m) = 0.36340868f0\n",
      "loss_all(train_data, m) = 0.3630237f0\n",
      "loss_all(train_data, m) = 0.36264846f0\n",
      "loss_all(train_data, m) = 0.36226544f0\n",
      "loss_all(train_data, m) = 0.36189532f0\n",
      "loss_all(train_data, m) = 0.3615465f0\n",
      "loss_all(train_data, m) = 0.36117125f0\n",
      "loss_all(train_data, m) = 0.3607373f0\n",
      "loss_all(train_data, m) = 0.3603083f0\n",
      "loss_all(train_data, m) = 0.35989836f0\n",
      "loss_all(train_data, m) = 0.35950246f0\n",
      "loss_all(train_data, m) = 0.35911036f0\n",
      "loss_all(train_data, m) = 0.35872418f0\n",
      "loss_all(train_data, m) = 0.35834667f0\n",
      "loss_all(train_data, m) = 0.35800594f0\n",
      "loss_all(train_data, m) = 0.35767546f0\n",
      "loss_all(train_data, m) = 0.3573604f0\n",
      "loss_all(train_data, m) = 0.35703632f0\n",
      "loss_all(train_data, m) = 0.3566972f0\n",
      "loss_all(train_data, m) = 0.35631153f0\n",
      "loss_all(train_data, m) = 0.35588688f0\n",
      "loss_all(train_data, m) = 0.35545647f0\n",
      "loss_all(train_data, m) = 0.35504833f0\n",
      "loss_all(train_data, m) = 0.3546449f0\n",
      "loss_all(train_data, m) = 0.3542454f0\n",
      "loss_all(train_data, m) = 0.35390133f0\n",
      "loss_all(train_data, m) = 0.35358498f0\n",
      "loss_all(train_data, m) = 0.35328233f0\n",
      "loss_all(train_data, m) = 0.3529767f0\n",
      "loss_all(train_data, m) = 0.35264084f0\n",
      "loss_all(train_data, m) = 0.35231134f0\n",
      "loss_all(train_data, m) = 0.35199323f0\n",
      "loss_all(train_data, m) = 0.35166037f0\n",
      "loss_all(train_data, m) = 0.35132444f0\n",
      "loss_all(train_data, m) = 0.35095954f0\n",
      "loss_all(train_data, m) = 0.35056475f0\n",
      "loss_all(train_data, m) = 0.35015994f0\n",
      "loss_all(train_data, m) = 0.34976527f0\n",
      "loss_all(train_data, m) = 0.34938753f0\n",
      "loss_all(train_data, m) = 0.34902674f0\n",
      "loss_all(train_data, m) = 0.3486754f0\n",
      "loss_all(train_data, m) = 0.34834567f0\n",
      "loss_all(train_data, m) = 0.34800085f0\n",
      "loss_all(train_data, m) = 0.3476628f0\n",
      "loss_all(train_data, m) = 0.34733215f0\n",
      "loss_all(train_data, m) = 0.34697652f0\n",
      "loss_all(train_data, m) = 0.34663635f0\n",
      "loss_all(train_data, m) = 0.3463078f0\n",
      "loss_all(train_data, m) = 0.34602493f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_all(train_data, m) = 0.34577948f0\n",
      "loss_all(train_data, m) = 0.34548798f0\n",
      "loss_all(train_data, m) = 0.34517133f0\n",
      "loss_all(train_data, m) = 0.34481224f0\n",
      "loss_all(train_data, m) = 0.3444497f0\n",
      "loss_all(train_data, m) = 0.34408844f0\n",
      "loss_all(train_data, m) = 0.34372553f0\n",
      "loss_all(train_data, m) = 0.34337807f0\n",
      "loss_all(train_data, m) = 0.34304422f0\n",
      "loss_all(train_data, m) = 0.342702f0\n",
      "loss_all(train_data, m) = 0.34241492f0\n",
      "loss_all(train_data, m) = 0.34212098f0\n",
      "loss_all(train_data, m) = 0.3418367f0\n",
      "loss_all(train_data, m) = 0.34154445f0\n",
      "loss_all(train_data, m) = 0.34126258f0\n",
      "loss_all(train_data, m) = 0.34100166f0\n",
      "loss_all(train_data, m) = 0.34071174f0\n",
      "loss_all(train_data, m) = 0.3403573f0\n",
      "loss_all(train_data, m) = 0.34000376f0\n",
      "loss_all(train_data, m) = 0.339669f0\n",
      "loss_all(train_data, m) = 0.33934915f0\n",
      "loss_all(train_data, m) = 0.3390324f0\n",
      "loss_all(train_data, m) = 0.33872104f0\n",
      "loss_all(train_data, m) = 0.33841816f0\n",
      "loss_all(train_data, m) = 0.3381539f0\n",
      "loss_all(train_data, m) = 0.33790097f0\n",
      "loss_all(train_data, m) = 0.33766514f0\n",
      "loss_all(train_data, m) = 0.33741912f0\n",
      "loss_all(train_data, m) = 0.33715755f0\n",
      "loss_all(train_data, m) = 0.33685076f0\n",
      "loss_all(train_data, m) = 0.33650675f0\n",
      "loss_all(train_data, m) = 0.33615506f0\n",
      "loss_all(train_data, m) = 0.33582565f0\n",
      "loss_all(train_data, m) = 0.33549806f0\n",
      "loss_all(train_data, m) = 0.33517274f0\n",
      "loss_all(train_data, m) = 0.33490247f0\n",
      "loss_all(train_data, m) = 0.33465722f0\n",
      "loss_all(train_data, m) = 0.3344257f0\n",
      "loss_all(train_data, m) = 0.33418986f0\n",
      "loss_all(train_data, m) = 0.33392414f0\n",
      "loss_all(train_data, m) = 0.33366355f0\n",
      "loss_all(train_data, m) = 0.33341688f0\n",
      "loss_all(train_data, m) = 0.3331567f0\n",
      "loss_all(train_data, m) = 0.33289388f0\n",
      "loss_all(train_data, m) = 0.33260095f0\n",
      "loss_all(train_data, m) = 0.33227688f0\n",
      "loss_all(train_data, m) = 0.3319424f0\n",
      "loss_all(train_data, m) = 0.331618f0\n",
      "loss_all(train_data, m) = 0.33130768f0\n",
      "loss_all(train_data, m) = 0.33101308f0\n",
      "loss_all(train_data, m) = 0.33072585f0\n",
      "loss_all(train_data, m) = 0.33046183f0\n",
      "loss_all(train_data, m) = 0.33018047f0\n",
      "loss_all(train_data, m) = 0.32990485f0\n",
      "loss_all(train_data, m) = 0.3296379f0\n",
      "loss_all(train_data, m) = 0.32935035f0\n",
      "loss_all(train_data, m) = 0.32908186f0\n",
      "loss_all(train_data, m) = 0.3288251f0\n",
      "loss_all(train_data, m) = 0.3286095f0\n",
      "loss_all(train_data, m) = 0.32843006f0\n",
      "loss_all(train_data, m) = 0.3282022f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\racinsky\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.32795027f0\n",
      "loss_all(train_data, m) = 0.327653f0\n",
      "loss_all(train_data, m) = 0.32735053f0\n",
      "loss_all(train_data, m) = 0.32705027f0\n",
      "loss_all(train_data, m) = 0.32674813f0\n",
      "loss_all(train_data, m) = 0.32646185f0\n",
      "loss_all(train_data, m) = 0.32618856f0\n",
      "loss_all(train_data, m) = 0.32590485f0\n",
      "loss_all(train_data, m) = 0.32567945f0\n",
      "loss_all(train_data, m) = 0.32544687f0\n",
      "loss_all(train_data, m) = 0.32522225f0\n",
      "loss_all(train_data, m) = 0.32499117f0\n",
      "loss_all(train_data, m) = 0.3247693f0\n",
      "loss_all(train_data, m) = 0.32456863f0\n",
      "loss_all(train_data, m) = 0.3243359f0\n",
      "loss_all(train_data, m) = 0.3240318f0\n",
      "loss_all(train_data, m) = 0.32372582f0\n",
      "loss_all(train_data, m) = 0.32343975f0\n",
      "loss_all(train_data, m) = 0.32317f0\n",
      "loss_all(train_data, m) = 0.3229035f0\n",
      "loss_all(train_data, m) = 0.32264292f0\n",
      "loss_all(train_data, m) = 0.32239106f0\n",
      "loss_all(train_data, m) = 0.32217875f0\n",
      "loss_all(train_data, m) = 0.32197762f0\n",
      "loss_all(train_data, m) = 0.32179475f0\n",
      "loss_all(train_data, m) = 0.32159942f0\n",
      "loss_all(train_data, m) = 0.32138884f0\n",
      "loss_all(train_data, m) = 0.32113498f0\n",
      "loss_all(train_data, m) = 0.3208463f0\n",
      "loss_all(train_data, m) = 0.3205495f0\n",
      "loss_all(train_data, m) = 0.32027462f0\n",
      "loss_all(train_data, m) = 0.32000166f0\n",
      "loss_all(train_data, m) = 0.31972876f0\n",
      "loss_all(train_data, m) = 0.31950963f0\n",
      "loss_all(train_data, m) = 0.3193146f0\n",
      "loss_all(train_data, m) = 0.3191311f0\n",
      "loss_all(train_data, m) = 0.31894466f0\n",
      "loss_all(train_data, m) = 0.31872946f0\n",
      "loss_all(train_data, m) = 0.31851834f0\n",
      "loss_all(train_data, m) = 0.31832173f0\n",
      "loss_all(train_data, m) = 0.3181129f0\n",
      "loss_all(train_data, m) = 0.3179011f0\n",
      "loss_all(train_data, m) = 0.31766003f0\n",
      "loss_all(train_data, m) = 0.31738627f0\n",
      "loss_all(train_data, m) = 0.3170994f0\n",
      "loss_all(train_data, m) = 0.31682438f0\n",
      "loss_all(train_data, m) = 0.31656003f0\n",
      "loss_all(train_data, m) = 0.3163113f0\n",
      "loss_all(train_data, m) = 0.31607196f0\n",
      "loss_all(train_data, m) = 0.3158574f0\n",
      "loss_all(train_data, m) = 0.31562352f0\n",
      "loss_all(train_data, m) = 0.31539506f0\n",
      "loss_all(train_data, m) = 0.3151775f0\n",
      "loss_all(train_data, m) = 0.31494036f0\n",
      "loss_all(train_data, m) = 0.31472307f0\n",
      "loss_all(train_data, m) = 0.31451514f0\n"
     ]
    }
   ],
   "source": [
    "@epochs args.epochs Flux.train!(loss, params(m), train_data, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(train_data, m) = 0.9157934809879572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9157934809879572"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show accuracy(train_data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(test_data, m) = 0.9196687659438776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9196687659438776"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show accuracy(test_data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mb, y_mb = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element CUDA.CuArray{Float32,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_mb[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Flux.OneHotVector:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_mb[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Tuple{Int64,Vararg{Int64,N} where N},1}:\n",
       " (32, 784)\n",
       " (32,)\n",
       " (10, 32)\n",
       " (10,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size.(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25450"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (32* 784) + 32 + (10* 32) +(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.46173469387755"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25450/784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25120"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32* 784) + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Tuple{Int64,Vararg{Int64,N} where N},1}:\n",
       " (32, 784)\n",
       " (32,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(Chain(Dense(784, 32))) .|> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25120"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (32* 784) + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Tuple{Int64,Vararg{Int64,N} where N},1}:\n",
       " (3, 3, 1, 16)\n",
       " (16,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(Chain(Conv((3, 3), 1=>16, pad=(1,1), relu))) .|> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*3*1*16+16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 CUDA.CuArray{Float32,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0       …  0.282353  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.682353  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0431373  0.145098     0.984314  0.0  0.0  0.0  0.0\n",
       " ⋮                              ⋮         ⋱                 ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.121569   0.419608     0.117647  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0          0.0       0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape(x, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip130\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip130)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip131\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip130)\" d=\"\n",
       "M524.751 1486.45 L1963.95 1486.45 L1963.95 47.2441 L524.751 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip132\">\n",
       "    <rect x=\"524\" y=\"47\" width=\"1440\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  737.967,47.2441 737.967,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1004.49,47.2441 1004.49,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1271,47.2441 1271,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1537.52,47.2441 1537.52,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1804.04,47.2441 1804.04,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1486.45 1963.95,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  737.967,1486.45 737.967,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1004.49,1486.45 1004.49,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1271,1486.45 1271,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1537.52,1486.45 1537.52,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1804.04,1486.45 1804.04,1469.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"M 0 0 M728.244 1512.56 L746.601 1512.56 L746.601 1516.5 L732.527 1516.5 L732.527 1524.97 Q733.545 1524.62 734.564 1524.46 Q735.582 1524.27 736.601 1524.27 Q742.388 1524.27 745.767 1527.44 Q749.147 1530.62 749.147 1536.03 Q749.147 1541.61 745.675 1544.71 Q742.203 1547.79 735.883 1547.79 Q733.707 1547.79 731.439 1547.42 Q729.193 1547.05 726.786 1546.31 L726.786 1541.61 Q728.869 1542.74 731.092 1543.3 Q733.314 1543.86 735.791 1543.86 Q739.795 1543.86 742.133 1541.75 Q744.471 1539.64 744.471 1536.03 Q744.471 1532.42 742.133 1530.31 Q739.795 1528.21 735.791 1528.21 Q733.916 1528.21 732.041 1528.62 Q730.189 1529.04 728.244 1529.92 L728.244 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M981.361 1543.18 L989 1543.18 L989 1516.82 L980.69 1518.49 L980.69 1514.23 L988.953 1512.56 L993.629 1512.56 L993.629 1543.18 L1001.27 1543.18 L1001.27 1547.12 L981.361 1547.12 L981.361 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1016.34 1515.64 Q1012.73 1515.64 1010.9 1519.2 Q1009.09 1522.75 1009.09 1529.87 Q1009.09 1536.98 1010.9 1540.55 Q1012.73 1544.09 1016.34 1544.09 Q1019.97 1544.09 1021.78 1540.55 Q1023.61 1536.98 1023.61 1529.87 Q1023.61 1522.75 1021.78 1519.2 Q1019.97 1515.64 1016.34 1515.64 M1016.34 1511.93 Q1022.15 1511.93 1025.2 1516.54 Q1028.28 1521.12 1028.28 1529.87 Q1028.28 1538.6 1025.2 1543.21 Q1022.15 1547.79 1016.34 1547.79 Q1010.53 1547.79 1007.45 1543.21 Q1004.39 1538.6 1004.39 1529.87 Q1004.39 1521.12 1007.45 1516.54 Q1010.53 1511.93 1016.34 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1248.38 1543.18 L1256.02 1543.18 L1256.02 1516.82 L1247.71 1518.49 L1247.71 1514.23 L1255.97 1512.56 L1260.65 1512.56 L1260.65 1543.18 L1268.29 1543.18 L1268.29 1547.12 L1248.38 1547.12 L1248.38 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1273.4 1512.56 L1291.76 1512.56 L1291.76 1516.5 L1277.68 1516.5 L1277.68 1524.97 Q1278.7 1524.62 1279.72 1524.46 Q1280.74 1524.27 1281.76 1524.27 Q1287.54 1524.27 1290.92 1527.44 Q1294.3 1530.62 1294.3 1536.03 Q1294.3 1541.61 1290.83 1544.71 Q1287.36 1547.79 1281.04 1547.79 Q1278.86 1547.79 1276.6 1547.42 Q1274.35 1547.05 1271.94 1546.31 L1271.94 1541.61 Q1274.03 1542.74 1276.25 1543.3 Q1278.47 1543.86 1280.95 1543.86 Q1284.95 1543.86 1287.29 1541.75 Q1289.63 1539.64 1289.63 1536.03 Q1289.63 1532.42 1287.29 1530.31 Q1284.95 1528.21 1280.95 1528.21 Q1279.07 1528.21 1277.2 1528.62 Q1275.35 1529.04 1273.4 1529.92 L1273.4 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1518.67 1543.18 L1534.99 1543.18 L1534.99 1547.12 L1513.05 1547.12 L1513.05 1543.18 Q1515.71 1540.43 1520.29 1535.8 Q1524.9 1531.15 1526.08 1529.81 Q1528.32 1527.28 1529.2 1525.55 Q1530.11 1523.79 1530.11 1522.1 Q1530.11 1519.34 1528.16 1517.61 Q1526.24 1515.87 1523.14 1515.87 Q1520.94 1515.87 1518.48 1516.63 Q1516.05 1517.4 1513.28 1518.95 L1513.28 1514.23 Q1516.1 1513.09 1518.55 1512.51 Q1521.01 1511.93 1523.05 1511.93 Q1528.42 1511.93 1531.61 1514.62 Q1534.8 1517.31 1534.8 1521.8 Q1534.8 1523.93 1533.99 1525.85 Q1533.21 1527.74 1531.1 1530.34 Q1530.52 1531.01 1527.42 1534.23 Q1524.32 1537.42 1518.67 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1550.06 1515.64 Q1546.45 1515.64 1544.62 1519.2 Q1542.81 1522.75 1542.81 1529.87 Q1542.81 1536.98 1544.62 1540.55 Q1546.45 1544.09 1550.06 1544.09 Q1553.69 1544.09 1555.5 1540.55 Q1557.33 1536.98 1557.33 1529.87 Q1557.33 1522.75 1555.5 1519.2 Q1553.69 1515.64 1550.06 1515.64 M1550.06 1511.93 Q1555.87 1511.93 1558.92 1516.54 Q1562 1521.12 1562 1529.87 Q1562 1538.6 1558.92 1543.21 Q1555.87 1547.79 1550.06 1547.79 Q1544.25 1547.79 1541.17 1543.21 Q1538.11 1538.6 1538.11 1529.87 Q1538.11 1521.12 1541.17 1516.54 Q1544.25 1511.93 1550.06 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1785.69 1543.18 L1802.01 1543.18 L1802.01 1547.12 L1780.06 1547.12 L1780.06 1543.18 Q1782.72 1540.43 1787.31 1535.8 Q1791.91 1531.15 1793.09 1529.81 Q1795.34 1527.28 1796.22 1525.55 Q1797.12 1523.79 1797.12 1522.1 Q1797.12 1519.34 1795.18 1517.61 Q1793.26 1515.87 1790.15 1515.87 Q1787.96 1515.87 1785.5 1516.63 Q1783.07 1517.4 1780.29 1518.95 L1780.29 1514.23 Q1783.12 1513.09 1785.57 1512.51 Q1788.02 1511.93 1790.06 1511.93 Q1795.43 1511.93 1798.63 1514.62 Q1801.82 1517.31 1801.82 1521.8 Q1801.82 1523.93 1801.01 1525.85 Q1800.22 1527.74 1798.12 1530.34 Q1797.54 1531.01 1794.44 1534.23 Q1791.34 1537.42 1785.69 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M1807.12 1512.56 L1825.48 1512.56 L1825.48 1516.5 L1811.4 1516.5 L1811.4 1524.97 Q1812.42 1524.62 1813.44 1524.46 Q1814.46 1524.27 1815.48 1524.27 Q1821.27 1524.27 1824.65 1527.44 Q1828.02 1530.62 1828.02 1536.03 Q1828.02 1541.61 1824.55 1544.71 Q1821.08 1547.79 1814.76 1547.79 Q1812.59 1547.79 1810.32 1547.42 Q1808.07 1547.05 1805.66 1546.31 L1805.66 1541.61 Q1807.75 1542.74 1809.97 1543.3 Q1812.19 1543.86 1814.67 1543.86 Q1818.67 1543.86 1821.01 1541.75 Q1823.35 1539.64 1823.35 1536.03 Q1823.35 1532.42 1821.01 1530.31 Q1818.67 1528.21 1814.67 1528.21 Q1812.79 1528.21 1810.92 1528.62 Q1809.07 1529.04 1807.12 1529.92 L1807.12 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,260.459 1963.95,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,526.979 1963.95,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,793.498 1963.95,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1060.02 1963.95,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1326.54 1963.95,1326.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,47.2441 524.751,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,260.459 542.022,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,526.979 542.022,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,793.498 542.022,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1060.02 542.022,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1326.54 542.022,1326.54 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"M 0 0 M467.848 243.179 L486.205 243.179 L486.205 247.115 L472.131 247.115 L472.131 255.587 Q473.149 255.24 474.168 255.078 Q475.186 254.892 476.205 254.892 Q481.992 254.892 485.372 258.064 Q488.751 261.235 488.751 266.652 Q488.751 272.23 485.279 275.332 Q481.807 278.411 475.487 278.411 Q473.311 278.411 471.043 278.04 Q468.798 277.67 466.39 276.929 L466.39 272.23 Q468.473 273.364 470.696 273.92 Q472.918 274.476 475.395 274.476 Q479.399 274.476 481.737 272.369 Q484.075 270.263 484.075 266.652 Q484.075 263.04 481.737 260.934 Q479.399 258.828 475.395 258.828 Q473.52 258.828 471.645 259.244 Q469.793 259.661 467.848 260.54 L467.848 243.179 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M441.83 540.324 L449.469 540.324 L449.469 513.958 L441.159 515.625 L441.159 511.365 L449.423 509.699 L454.099 509.699 L454.099 540.324 L461.737 540.324 L461.737 544.259 L441.83 544.259 L441.83 540.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M476.807 512.777 Q473.196 512.777 471.367 516.342 Q469.561 519.884 469.561 527.013 Q469.561 534.12 471.367 537.685 Q473.196 541.226 476.807 541.226 Q480.441 541.226 482.247 537.685 Q484.075 534.12 484.075 527.013 Q484.075 519.884 482.247 516.342 Q480.441 512.777 476.807 512.777 M476.807 509.074 Q482.617 509.074 485.672 513.68 Q488.751 518.263 488.751 527.013 Q488.751 535.74 485.672 540.347 Q482.617 544.93 476.807 544.93 Q470.997 544.93 467.918 540.347 Q464.862 535.74 464.862 527.013 Q464.862 518.263 467.918 513.68 Q470.997 509.074 476.807 509.074 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M442.825 806.843 L450.464 806.843 L450.464 780.477 L442.154 782.144 L442.154 777.885 L450.418 776.218 L455.094 776.218 L455.094 806.843 L462.733 806.843 L462.733 810.778 L442.825 810.778 L442.825 806.843 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M467.848 776.218 L486.205 776.218 L486.205 780.153 L472.131 780.153 L472.131 788.625 Q473.149 788.278 474.168 788.116 Q475.186 787.931 476.205 787.931 Q481.992 787.931 485.372 791.102 Q488.751 794.273 488.751 799.69 Q488.751 805.269 485.279 808.371 Q481.807 811.449 475.487 811.449 Q473.311 811.449 471.043 811.079 Q468.798 810.708 466.39 809.968 L466.39 805.269 Q468.473 806.403 470.696 806.958 Q472.918 807.514 475.395 807.514 Q479.399 807.514 481.737 805.408 Q484.075 803.301 484.075 799.69 Q484.075 796.079 481.737 793.972 Q479.399 791.866 475.395 791.866 Q473.52 791.866 471.645 792.283 Q469.793 792.699 467.848 793.579 L467.848 776.218 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M445.418 1073.36 L461.737 1073.36 L461.737 1077.3 L439.793 1077.3 L439.793 1073.36 Q442.455 1070.61 447.038 1065.98 Q451.645 1061.32 452.825 1059.98 Q455.071 1057.46 455.95 1055.72 Q456.853 1053.96 456.853 1052.27 Q456.853 1049.52 454.909 1047.78 Q452.987 1046.05 449.886 1046.05 Q447.687 1046.05 445.233 1046.81 Q442.802 1047.58 440.025 1049.13 L440.025 1044.4 Q442.849 1043.27 445.302 1042.69 Q447.756 1042.11 449.793 1042.11 Q455.163 1042.11 458.358 1044.8 Q461.552 1047.48 461.552 1051.97 Q461.552 1054.1 460.742 1056.02 Q459.955 1057.92 457.849 1060.51 Q457.27 1061.19 454.168 1064.4 Q451.066 1067.6 445.418 1073.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M476.807 1045.82 Q473.196 1045.82 471.367 1049.38 Q469.561 1052.92 469.561 1060.05 Q469.561 1067.16 471.367 1070.72 Q473.196 1074.26 476.807 1074.26 Q480.441 1074.26 482.247 1070.72 Q484.075 1067.16 484.075 1060.05 Q484.075 1052.92 482.247 1049.38 Q480.441 1045.82 476.807 1045.82 M476.807 1042.11 Q482.617 1042.11 485.672 1046.72 Q488.751 1051.3 488.751 1060.05 Q488.751 1068.78 485.672 1073.39 Q482.617 1077.97 476.807 1077.97 Q470.997 1077.97 467.918 1073.39 Q464.862 1068.78 464.862 1060.05 Q464.862 1051.3 467.918 1046.72 Q470.997 1042.11 476.807 1042.11 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M446.413 1339.88 L462.733 1339.88 L462.733 1343.82 L440.788 1343.82 L440.788 1339.88 Q443.45 1337.13 448.034 1332.5 Q452.64 1327.84 453.821 1326.5 Q456.066 1323.98 456.946 1322.24 Q457.849 1320.48 457.849 1318.79 Q457.849 1316.04 455.904 1314.3 Q453.983 1312.57 450.881 1312.57 Q448.682 1312.57 446.228 1313.33 Q443.798 1314.09 441.02 1315.65 L441.02 1310.92 Q443.844 1309.79 446.298 1309.21 Q448.751 1308.63 450.788 1308.63 Q456.159 1308.63 459.353 1311.32 Q462.548 1314 462.548 1318.49 Q462.548 1320.62 461.737 1322.54 Q460.95 1324.44 458.844 1327.03 Q458.265 1327.71 455.163 1330.92 Q452.062 1334.12 446.413 1339.88 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M 0 0 M467.848 1309.26 L486.205 1309.26 L486.205 1313.19 L472.131 1313.19 L472.131 1321.66 Q473.149 1321.32 474.168 1321.15 Q475.186 1320.97 476.205 1320.97 Q481.992 1320.97 485.372 1324.14 Q488.751 1327.31 488.751 1332.73 Q488.751 1338.31 485.279 1341.41 Q481.807 1344.49 475.487 1344.49 Q473.311 1344.49 471.043 1344.12 Q468.798 1343.75 466.39 1343.01 L466.39 1338.31 Q468.473 1339.44 470.696 1340 Q472.918 1340.55 475.395 1340.55 Q479.399 1340.55 481.737 1338.45 Q484.075 1336.34 484.075 1332.73 Q484.075 1329.12 481.737 1327.01 Q479.399 1324.9 475.395 1324.9 Q473.52 1324.9 471.645 1325.32 Q469.793 1325.74 467.848 1326.62 L467.848 1309.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><g clip-path=\"url(#clip132)\">\n",
       "<image width=\"1493\" height=\"1493\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAABdUAAAXVCAYAAADjLzZmAAAgAElEQVR4nOzaIW5UaxyH4dMBh6W6\n",
       "mAZWgIQEh8MQ2AFB0A2QkKBJUBCQbACLwJBgUBWYOkQ9CBJCSAjTuwIuL8k592vPfZ4V/Ma037zz\n",
       "35mm6WQCAAAAAAD+aDN6AAAAAAAAnBWiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAETnRw8AAOC/deHChdETZvfkyZPRExZx79690RMWcXh4OHrC7G7fvj16\n",
       "wmyOj49HTwAAONVcqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAA\n",
       "QCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "JKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSq\n",
       "AwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAtDNN08noEQAA/Hf29/dHT5jd0dHR\n",
       "6An8hc1mfbc9BwcHoyfM5vnz56MnAACcaut7zQIAAAAAwEJEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiM6PHgAAcBbs7u6OnjCbV69ejZ4AAABwZrlUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIDo/OgBAMC6HBwcjJ6wiFu3bo2eMJurV6+OngCrc+3atdETZrPZ\n",
       "rPP26uPHj6MnLOL9+/ejJwDA/846X0sAAAAAALAAUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0A\n",
       "AAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAA\n",
       "AAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAA\n",
       "AAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAA\n",
       "ACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAA\n",
       "IlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAi\n",
       "UR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJR\n",
       "HQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAACinWmaTkaPAADW49evX6MnLGK7\n",
       "3Y6eAKux2azvtsffiNPv+Ph49IRF3LlzZ/SERRweHo6eAAC/tb7XLAAAAAAALERUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACAaGeappPRIwDg/+jNmzejJyzi5s2boycsYrvdjp4Aq/Hly5fRE2b37du30RNms7e3N3oC\n",
       "TOfOnRs9AQB+y6U6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAETnRw8AgD+5fv366AmLuHz58ugJi9hu\n",
       "t6MnLGKtn4vT7eXLl6MnLOLt27ejJ8zu69evoyfM5saNG6MnLOLhw4ejJ/AX7t+/P3rC7F68eDF6\n",
       "AgAzcakOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAA\n",
       "AACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAANHONE0no0cAMJ9Lly6NnjC7Dx8+jJ6wiIsXL46e\n",
       "sIjNZp2/2W+329ETZnN8fDx6wuxev349esIiHj9+PHrCIr5//z56Av9ib29v9IRFrPU9sbu7O3rC\n",
       "In78+DF6wuwePXo0esIinj17NnrCbH7+/Dl6AnBGrPNbLwAAAAAALEBUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACAaGeappPRIwCYz/7+/ugJszs6Oho9gb+w\n",
       "2azzN/t3796NnjCbu3fvjp4wu8+fP4+eAJxyDx48GD1hEU+fPh09YRFrfE9st9vRExZx5cqV0RNm\n",
       "8+nTp9ETgDNiff+lAAAAAABgIaI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AADAP+zaMYpUaRuG4aqmt2BgZCiYGYiZsQM2mGsgBhoImmsgpuai6C4acQMGJsZ2\n",
       "KiYiGpsI5b+AH2fugXN8p8vrWsFTVHHq4z4fAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARIfTAwCA/fL+/fvpCau4\n",
       "ffv29ITFfPv2bXoCwG93fHw8PWEVN27cmJ6wikuXLk1PAIBfclMdAAAAAAAiUR0AAAAAACJRHQAA\n",
       "AAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAA\n",
       "AAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAA\n",
       "ACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAA\n",
       "IlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAi\n",
       "UR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJR\n",
       "HQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEd\n",
       "AAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0A\n",
       "AAAAAKLD6QEA8E8ODrwDPk0uX748PQEA/s92u52esIp9PSft6+faR0+ePJmesJibN29OTwBOCf9S\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABAdTg8AYFl3796dnrC43W43PQEAOOWOjo6mJ6zi4sWL0xNW\n",
       "sY/nv338TJvNZvP48ePpCQC/nZvqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQHU4PAGBZR0dH0xMA4I9z5syZ6QmL\n",
       "uXDhwvSEVTx8+HB6An+4r1+/Tk9YxY8fP6YnAPx2bqoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAA\n",
       "QCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "JKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQHQ4PQAAAOC0e/To0fSExdy7d296Amw+fvw4\n",
       "PWFxt27dmp6wik+fPk1PAPjt3FQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEUDOngAABNZSURBVEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgOhw\n",
       "egAAAPBnefPmzfSExZ0/f356AuyVk5OT6QmLe/v27fQEABbipjoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARIfTAwBY1na7nZ6wuIMD74BPk7/++mt6Av/g1atX0xMWd/bs2ekJ/Av7+Fzf7XbTE2CvXLt2\n",
       "bXoCAPzS/p1mAQAAAABgJaI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEh9MDAFjW8+fPpycs7unTp9MT+Bdev349\n",
       "PWEVu91uegJ/w/fDNL9Bprx48WJ6AgD8cdxUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACAaLvZbH5OjwBgOefOnZue\n",
       "sLh3795NT1jFmTNnpies4uBgP9/Z73a76QmwN/bxOfHly5fpCYs5OTmZnrCKO3fuTE9YxefPn6cn\n",
       "rOL79+/TEwDgl/bvNAsAAAAAACsR1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAA\n",
       "AAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAA\n",
       "ACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAA\n",
       "IBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAg\n",
       "EtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLV\n",
       "AQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUB\n",
       "AAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAINpuNpuf0yMA4O9cuXJlesIqrl+/\n",
       "Pj1hFQ8ePJiesIrdbjc9AfbGwcH+3e25f//+9ITFPHv2bHoCAMB/2v6dZgEAAAAAYCWiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARNvNZvNzegQAsD+uXr06\n",
       "PWEVd+7cmZ6wmKOjo+kJizs+Pp6esIqXL19OT1jFdrudnrC4Dx8+TE9YzKdPn6YnAAD8p7mpDgAA\n",
       "AAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAA\n",
       "AACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAADRdrPZ/JweAQAAAAAAp4Gb6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA8L92\n",
       "7EAAAAAAQJC/9QoDFEYAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAA\n",
       "mKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJ\n",
       "dQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoA\n",
       "AAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAA\n",
       "AABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAA\n",
       "wCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJ\n",
       "qgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QH\n",
       "AAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAA\n",
       "AAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAA\n",
       "ACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABM\n",
       "Uh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6\n",
       "AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAA\n",
       "AAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAA\n",
       "ADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABg\n",
       "kuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTV\n",
       "AQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIBJqgMA\n",
       "AAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAAk1QHAAAA\n",
       "AIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACapDgAAAAAA\n",
       "k1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0AAAAAACap\n",
       "DgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAAAABMUh0A\n",
       "AAAAACapDgAAAAAAk1QHAAAAAIBJqgMAAAAAwCTVAQAAAABgkuoAAAAAADBJdQAAAAAAmKQ6AAAA\n",
       "AABMUh0AAAAAACapDgAAAAAAk1QHAAAAAIAptTH8Iox5+wsAAAAASUVORK5CYII=\n",
       "\" transform=\"translate(498, 21)\"/>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Colors, Plots\n",
    "plot(Gray.(reshape(x, (28, 28))'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CUDA.CuArray{Float32,1}:\n",
       "  9.100636\n",
       " -7.244237\n",
       "  1.0222098\n",
       "  0.3414997\n",
       " -3.270363\n",
       "  2.0761306\n",
       "  2.4745414\n",
       "  2.2513554\n",
       "  0.15240425\n",
       "  0.11222842"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CUDA.CuArray{Float32,1}:\n",
       " 0.99601436\n",
       " 7.9392244f-8\n",
       " 0.00030892284\n",
       " 0.00015639434\n",
       " 4.222885f-6\n",
       " 0.0008862617\n",
       " 0.0013200475\n",
       " 0.0010559928\n",
       " 0.00012944879\n",
       " 0.0001243512"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 10 entries:\n",
       "  7  => 6\n",
       "  4  => 3\n",
       "  9  => 8\n",
       "  10 => 9\n",
       "  2  => 1\n",
       "  3  => 2\n",
       "  5  => 4\n",
       "  8  => 7\n",
       "  6  => 5\n",
       "  1  => 0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilabels = Dict(k=>v for (k,v) in enumerate(0:9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilabels[argmax(softmax(m(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilabels[argmax(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and now, convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bundle images together with labels and group into minibatchess\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "\n",
    "function get_processed_data(args)\n",
    "    # Load labels and images from Flux.Data.MNIST\n",
    "    train_labels = Flux.Data.MNIST.labels()\n",
    "    train_imgs = Flux.Data.MNIST.images()\n",
    "    mb_idxs = partition(1:length(train_imgs), args.batchsize)\n",
    "    train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs] \n",
    "    \n",
    "    # Prepare test set as one giant minibatch:\n",
    "    test_imgs = Flux.Data.MNIST.images(:test)\n",
    "    test_labels = Flux.Data.MNIST.labels(:test)\n",
    "    test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs))\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "end\n",
    "\n",
    "# Build model\n",
    "function build_model(args; imgsize = (28,28,1), nclasses = 10)\n",
    "    cnn_output_size = Int.(floor.([imgsize[1]/8,imgsize[2]/8,32]))\t\n",
    "\n",
    "    return Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), imgsize[3]=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one using `Flux.flatten`, at this point it should be (3, 3, 32, N)\n",
    "    flatten,\n",
    "    Dense(prod(cnn_output_size), 10))\n",
    "end\n",
    "\n",
    "# We augment `x` a little bit here, adding in random noise. \n",
    "augment(x) = x .+ gpu(0.1f0*randn(eltype(x), size(x)))\n",
    "\n",
    "# Returns a vector of all parameters used in model\n",
    "paramvec(m) = vcat(map(p->reshape(p, :), params(m))...)\n",
    "\n",
    "# Function to check if any element is NaN or not\n",
    "anynan(x) = any(isnan.(x))\n",
    "\n",
    "accuracy(x, y, model) = mean(onecold(cpu(model(x))) .== onecold(cpu(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading data set\n",
      "└ @ Main In[205]:1\n",
      "┌ Info: Building model...\n",
      "└ @ Main In[205]:6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×1024 CUDA.CuArray{Float32,2}:\n",
       " -0.152844   -0.0567296   -0.133809   …  -0.0971932   -0.156798   -0.16988\n",
       "  0.49274     0.48366      0.306898       0.386404     0.354929    0.28528\n",
       " -0.362488   -0.394094    -0.321329      -0.309374    -0.156161   -0.222034\n",
       " -0.553467   -0.478159    -0.328884      -0.459818    -0.338256   -0.324816\n",
       " -0.150685   -0.150046    -0.124735      -0.162954    -0.183706   -0.0779078\n",
       "  0.112264    0.215925     0.0372589  …   0.200659     0.0973102   0.1025\n",
       "  0.159455    0.175958     0.241634       0.109035     0.0602391   0.172034\n",
       "  0.115193    0.00751759   0.143929       0.0534566    0.0544095   0.131226\n",
       " -0.172827   -0.291618    -0.250652      -0.305815    -0.152088   -0.333183\n",
       " -0.0136642  -0.0106917    0.0938564      0.00201493  -0.0539994   0.0996487"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info(\"Loading data set\")\n",
    "train_set, test_set = get_processed_data(args)\n",
    "\n",
    "# Define our model.  We will use a simple convolutional architecture with\n",
    "# three iterations of Conv -> ReLU -> MaxPool, followed by a final Dense layer.\n",
    "@info(\"Building model...\")\n",
    "model = build_model(args) \n",
    "\n",
    "# Load model and datasets onto GPU, if enabled\n",
    "train_set = gpu.(train_set)\n",
    "test_set = gpu.(test_set)\n",
    "model = gpu(model)\n",
    "    \n",
    "# Make sure our model is nicely precompiled before starting our training loop\n",
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16938"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce.(*, size.(params(model))) |> sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67752"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16938/25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `loss()` calculates the crossentropy loss between our prediction `y_hat`\n",
    "# (calculated from `model(x)`) and the ground truth `y`.  We augment the data\n",
    "# a bit, adding gaussian random noise to our image to make it more robust.\n",
    "function loss(x, y)    \n",
    "    x̂ = augment(x)\n",
    "    ŷ = model(x̂)\n",
    "    return logitcrossentropy(ŷ, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), flatten, Dense(288, 10))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[213]:6\n",
      "┌ Info: [1]: Test accuracy: 0.9376\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [2]: Test accuracy: 0.9454\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [3]: Test accuracy: 0.9510\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [4]: Test accuracy: 0.9563\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [5]: Test accuracy: 0.9605\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [6]: Test accuracy: 0.9630\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [7]: Test accuracy: 0.9659\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [8]: Test accuracy: 0.9682\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [9]: Test accuracy: 0.9699\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n",
      "┌ Info: [10]: Test accuracy: 0.9712\n",
      "└ @ Main In[213]:22\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[213]:31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train our model with the given training set using the ADAM optimizer and\n",
    "# printing out performance against the test set as we go.\n",
    "opt = ADAM(args.η)\n",
    "best_model = nothing\n",
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:args.epochs\n",
    "    # Train for a single epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "    \n",
    "    # Terminate on NaN\n",
    "    if anynan(paramvec(model))\n",
    "        @error \"NaN params\"\n",
    "            break\n",
    "        end\n",
    "\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set..., model)\n",
    "\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to mnist_conv.bson\")\n",
    "        ispath(\"cnn_saved\") || mkpath(\"cnn_saved\")\n",
    "        BSON.@save joinpath(\"cnn_saved\", \"mnist_conv.bson\") params=cpu.(params(model)) epoch_idx acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "        best_model = model\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "   \n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(test_set..., best_model) = 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9712"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show accuracy(test_set...,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28×1×1 CUDA.CuArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.513726  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.592157  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮         ⋱                      ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_set[1][:, :, :, 50:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0f0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip210\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip210)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip211\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip210)\" d=\"\n",
       "M524.751 1486.45 L1963.95 1486.45 L1963.95 47.2441 L524.751 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip212\">\n",
       "    <rect x=\"524\" y=\"47\" width=\"1440\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  737.967,47.2441 737.967,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1004.49,47.2441 1004.49,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1271,47.2441 1271,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1537.52,47.2441 1537.52,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1804.04,47.2441 1804.04,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1486.45 1963.95,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  737.967,1486.45 737.967,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1004.49,1486.45 1004.49,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1271,1486.45 1271,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1537.52,1486.45 1537.52,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1804.04,1486.45 1804.04,1469.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M 0 0 M728.244 1512.56 L746.601 1512.56 L746.601 1516.5 L732.527 1516.5 L732.527 1524.97 Q733.545 1524.62 734.564 1524.46 Q735.582 1524.27 736.601 1524.27 Q742.388 1524.27 745.767 1527.44 Q749.147 1530.62 749.147 1536.03 Q749.147 1541.61 745.675 1544.71 Q742.203 1547.79 735.883 1547.79 Q733.707 1547.79 731.439 1547.42 Q729.193 1547.05 726.786 1546.31 L726.786 1541.61 Q728.869 1542.74 731.092 1543.3 Q733.314 1543.86 735.791 1543.86 Q739.795 1543.86 742.133 1541.75 Q744.471 1539.64 744.471 1536.03 Q744.471 1532.42 742.133 1530.31 Q739.795 1528.21 735.791 1528.21 Q733.916 1528.21 732.041 1528.62 Q730.189 1529.04 728.244 1529.92 L728.244 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M981.361 1543.18 L989 1543.18 L989 1516.82 L980.69 1518.49 L980.69 1514.23 L988.953 1512.56 L993.629 1512.56 L993.629 1543.18 L1001.27 1543.18 L1001.27 1547.12 L981.361 1547.12 L981.361 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1016.34 1515.64 Q1012.73 1515.64 1010.9 1519.2 Q1009.09 1522.75 1009.09 1529.87 Q1009.09 1536.98 1010.9 1540.55 Q1012.73 1544.09 1016.34 1544.09 Q1019.97 1544.09 1021.78 1540.55 Q1023.61 1536.98 1023.61 1529.87 Q1023.61 1522.75 1021.78 1519.2 Q1019.97 1515.64 1016.34 1515.64 M1016.34 1511.93 Q1022.15 1511.93 1025.2 1516.54 Q1028.28 1521.12 1028.28 1529.87 Q1028.28 1538.6 1025.2 1543.21 Q1022.15 1547.79 1016.34 1547.79 Q1010.53 1547.79 1007.45 1543.21 Q1004.39 1538.6 1004.39 1529.87 Q1004.39 1521.12 1007.45 1516.54 Q1010.53 1511.93 1016.34 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1248.38 1543.18 L1256.02 1543.18 L1256.02 1516.82 L1247.71 1518.49 L1247.71 1514.23 L1255.97 1512.56 L1260.65 1512.56 L1260.65 1543.18 L1268.29 1543.18 L1268.29 1547.12 L1248.38 1547.12 L1248.38 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1273.4 1512.56 L1291.76 1512.56 L1291.76 1516.5 L1277.68 1516.5 L1277.68 1524.97 Q1278.7 1524.62 1279.72 1524.46 Q1280.74 1524.27 1281.76 1524.27 Q1287.54 1524.27 1290.92 1527.44 Q1294.3 1530.62 1294.3 1536.03 Q1294.3 1541.61 1290.83 1544.71 Q1287.36 1547.79 1281.04 1547.79 Q1278.86 1547.79 1276.6 1547.42 Q1274.35 1547.05 1271.94 1546.31 L1271.94 1541.61 Q1274.03 1542.74 1276.25 1543.3 Q1278.47 1543.86 1280.95 1543.86 Q1284.95 1543.86 1287.29 1541.75 Q1289.63 1539.64 1289.63 1536.03 Q1289.63 1532.42 1287.29 1530.31 Q1284.95 1528.21 1280.95 1528.21 Q1279.07 1528.21 1277.2 1528.62 Q1275.35 1529.04 1273.4 1529.92 L1273.4 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1518.67 1543.18 L1534.99 1543.18 L1534.99 1547.12 L1513.05 1547.12 L1513.05 1543.18 Q1515.71 1540.43 1520.29 1535.8 Q1524.9 1531.15 1526.08 1529.81 Q1528.32 1527.28 1529.2 1525.55 Q1530.11 1523.79 1530.11 1522.1 Q1530.11 1519.34 1528.16 1517.61 Q1526.24 1515.87 1523.14 1515.87 Q1520.94 1515.87 1518.48 1516.63 Q1516.05 1517.4 1513.28 1518.95 L1513.28 1514.23 Q1516.1 1513.09 1518.55 1512.51 Q1521.01 1511.93 1523.05 1511.93 Q1528.42 1511.93 1531.61 1514.62 Q1534.8 1517.31 1534.8 1521.8 Q1534.8 1523.93 1533.99 1525.85 Q1533.21 1527.74 1531.1 1530.34 Q1530.52 1531.01 1527.42 1534.23 Q1524.32 1537.42 1518.67 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1550.06 1515.64 Q1546.45 1515.64 1544.62 1519.2 Q1542.81 1522.75 1542.81 1529.87 Q1542.81 1536.98 1544.62 1540.55 Q1546.45 1544.09 1550.06 1544.09 Q1553.69 1544.09 1555.5 1540.55 Q1557.33 1536.98 1557.33 1529.87 Q1557.33 1522.75 1555.5 1519.2 Q1553.69 1515.64 1550.06 1515.64 M1550.06 1511.93 Q1555.87 1511.93 1558.92 1516.54 Q1562 1521.12 1562 1529.87 Q1562 1538.6 1558.92 1543.21 Q1555.87 1547.79 1550.06 1547.79 Q1544.25 1547.79 1541.17 1543.21 Q1538.11 1538.6 1538.11 1529.87 Q1538.11 1521.12 1541.17 1516.54 Q1544.25 1511.93 1550.06 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1785.69 1543.18 L1802.01 1543.18 L1802.01 1547.12 L1780.06 1547.12 L1780.06 1543.18 Q1782.72 1540.43 1787.31 1535.8 Q1791.91 1531.15 1793.09 1529.81 Q1795.34 1527.28 1796.22 1525.55 Q1797.12 1523.79 1797.12 1522.1 Q1797.12 1519.34 1795.18 1517.61 Q1793.26 1515.87 1790.15 1515.87 Q1787.96 1515.87 1785.5 1516.63 Q1783.07 1517.4 1780.29 1518.95 L1780.29 1514.23 Q1783.12 1513.09 1785.57 1512.51 Q1788.02 1511.93 1790.06 1511.93 Q1795.43 1511.93 1798.63 1514.62 Q1801.82 1517.31 1801.82 1521.8 Q1801.82 1523.93 1801.01 1525.85 Q1800.22 1527.74 1798.12 1530.34 Q1797.54 1531.01 1794.44 1534.23 Q1791.34 1537.42 1785.69 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M1807.12 1512.56 L1825.48 1512.56 L1825.48 1516.5 L1811.4 1516.5 L1811.4 1524.97 Q1812.42 1524.62 1813.44 1524.46 Q1814.46 1524.27 1815.48 1524.27 Q1821.27 1524.27 1824.65 1527.44 Q1828.02 1530.62 1828.02 1536.03 Q1828.02 1541.61 1824.55 1544.71 Q1821.08 1547.79 1814.76 1547.79 Q1812.59 1547.79 1810.32 1547.42 Q1808.07 1547.05 1805.66 1546.31 L1805.66 1541.61 Q1807.75 1542.74 1809.97 1543.3 Q1812.19 1543.86 1814.67 1543.86 Q1818.67 1543.86 1821.01 1541.75 Q1823.35 1539.64 1823.35 1536.03 Q1823.35 1532.42 1821.01 1530.31 Q1818.67 1528.21 1814.67 1528.21 Q1812.79 1528.21 1810.92 1528.62 Q1809.07 1529.04 1807.12 1529.92 L1807.12 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,260.459 1963.95,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,526.979 1963.95,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,793.498 1963.95,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1060.02 1963.95,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  524.751,1326.54 1963.95,1326.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,47.2441 524.751,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,260.459 542.022,260.459 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,526.979 542.022,526.979 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,793.498 542.022,793.498 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1060.02 542.022,1060.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  524.751,1326.54 542.022,1326.54 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M 0 0 M467.848 243.179 L486.205 243.179 L486.205 247.115 L472.131 247.115 L472.131 255.587 Q473.149 255.24 474.168 255.078 Q475.186 254.892 476.205 254.892 Q481.992 254.892 485.372 258.064 Q488.751 261.235 488.751 266.652 Q488.751 272.23 485.279 275.332 Q481.807 278.411 475.487 278.411 Q473.311 278.411 471.043 278.04 Q468.798 277.67 466.39 276.929 L466.39 272.23 Q468.473 273.364 470.696 273.92 Q472.918 274.476 475.395 274.476 Q479.399 274.476 481.737 272.369 Q484.075 270.263 484.075 266.652 Q484.075 263.04 481.737 260.934 Q479.399 258.828 475.395 258.828 Q473.52 258.828 471.645 259.244 Q469.793 259.661 467.848 260.54 L467.848 243.179 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M441.83 540.324 L449.469 540.324 L449.469 513.958 L441.159 515.625 L441.159 511.365 L449.423 509.699 L454.099 509.699 L454.099 540.324 L461.737 540.324 L461.737 544.259 L441.83 544.259 L441.83 540.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M476.807 512.777 Q473.196 512.777 471.367 516.342 Q469.561 519.884 469.561 527.013 Q469.561 534.12 471.367 537.685 Q473.196 541.226 476.807 541.226 Q480.441 541.226 482.247 537.685 Q484.075 534.12 484.075 527.013 Q484.075 519.884 482.247 516.342 Q480.441 512.777 476.807 512.777 M476.807 509.074 Q482.617 509.074 485.672 513.68 Q488.751 518.263 488.751 527.013 Q488.751 535.74 485.672 540.347 Q482.617 544.93 476.807 544.93 Q470.997 544.93 467.918 540.347 Q464.862 535.74 464.862 527.013 Q464.862 518.263 467.918 513.68 Q470.997 509.074 476.807 509.074 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M442.825 806.843 L450.464 806.843 L450.464 780.477 L442.154 782.144 L442.154 777.885 L450.418 776.218 L455.094 776.218 L455.094 806.843 L462.733 806.843 L462.733 810.778 L442.825 810.778 L442.825 806.843 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M467.848 776.218 L486.205 776.218 L486.205 780.153 L472.131 780.153 L472.131 788.625 Q473.149 788.278 474.168 788.116 Q475.186 787.931 476.205 787.931 Q481.992 787.931 485.372 791.102 Q488.751 794.273 488.751 799.69 Q488.751 805.269 485.279 808.371 Q481.807 811.449 475.487 811.449 Q473.311 811.449 471.043 811.079 Q468.798 810.708 466.39 809.968 L466.39 805.269 Q468.473 806.403 470.696 806.958 Q472.918 807.514 475.395 807.514 Q479.399 807.514 481.737 805.408 Q484.075 803.301 484.075 799.69 Q484.075 796.079 481.737 793.972 Q479.399 791.866 475.395 791.866 Q473.52 791.866 471.645 792.283 Q469.793 792.699 467.848 793.579 L467.848 776.218 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M445.418 1073.36 L461.737 1073.36 L461.737 1077.3 L439.793 1077.3 L439.793 1073.36 Q442.455 1070.61 447.038 1065.98 Q451.645 1061.32 452.825 1059.98 Q455.071 1057.46 455.95 1055.72 Q456.853 1053.96 456.853 1052.27 Q456.853 1049.52 454.909 1047.78 Q452.987 1046.05 449.886 1046.05 Q447.687 1046.05 445.233 1046.81 Q442.802 1047.58 440.025 1049.13 L440.025 1044.4 Q442.849 1043.27 445.302 1042.69 Q447.756 1042.11 449.793 1042.11 Q455.163 1042.11 458.358 1044.8 Q461.552 1047.48 461.552 1051.97 Q461.552 1054.1 460.742 1056.02 Q459.955 1057.92 457.849 1060.51 Q457.27 1061.19 454.168 1064.4 Q451.066 1067.6 445.418 1073.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M476.807 1045.82 Q473.196 1045.82 471.367 1049.38 Q469.561 1052.92 469.561 1060.05 Q469.561 1067.16 471.367 1070.72 Q473.196 1074.26 476.807 1074.26 Q480.441 1074.26 482.247 1070.72 Q484.075 1067.16 484.075 1060.05 Q484.075 1052.92 482.247 1049.38 Q480.441 1045.82 476.807 1045.82 M476.807 1042.11 Q482.617 1042.11 485.672 1046.72 Q488.751 1051.3 488.751 1060.05 Q488.751 1068.78 485.672 1073.39 Q482.617 1077.97 476.807 1077.97 Q470.997 1077.97 467.918 1073.39 Q464.862 1068.78 464.862 1060.05 Q464.862 1051.3 467.918 1046.72 Q470.997 1042.11 476.807 1042.11 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M446.413 1339.88 L462.733 1339.88 L462.733 1343.82 L440.788 1343.82 L440.788 1339.88 Q443.45 1337.13 448.034 1332.5 Q452.64 1327.84 453.821 1326.5 Q456.066 1323.98 456.946 1322.24 Q457.849 1320.48 457.849 1318.79 Q457.849 1316.04 455.904 1314.3 Q453.983 1312.57 450.881 1312.57 Q448.682 1312.57 446.228 1313.33 Q443.798 1314.09 441.02 1315.65 L441.02 1310.92 Q443.844 1309.79 446.298 1309.21 Q448.751 1308.63 450.788 1308.63 Q456.159 1308.63 459.353 1311.32 Q462.548 1314 462.548 1318.49 Q462.548 1320.62 461.737 1322.54 Q460.95 1324.44 458.844 1327.03 Q458.265 1327.71 455.163 1330.92 Q452.062 1334.12 446.413 1339.88 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M 0 0 M467.848 1309.26 L486.205 1309.26 L486.205 1313.19 L472.131 1313.19 L472.131 1321.66 Q473.149 1321.32 474.168 1321.15 Q475.186 1320.97 476.205 1320.97 Q481.992 1320.97 485.372 1324.14 Q488.751 1327.31 488.751 1332.73 Q488.751 1338.31 485.279 1341.41 Q481.807 1344.49 475.487 1344.49 Q473.311 1344.49 471.043 1344.12 Q468.798 1343.75 466.39 1343.01 L466.39 1338.31 Q468.473 1339.44 470.696 1340 Q472.918 1340.55 475.395 1340.55 Q479.399 1340.55 481.737 1338.45 Q484.075 1336.34 484.075 1332.73 Q484.075 1329.12 481.737 1327.01 Q479.399 1324.9 475.395 1324.9 Q473.52 1324.9 471.645 1325.32 Q469.793 1325.74 467.848 1326.62 L467.848 1309.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><g clip-path=\"url(#clip212)\">\n",
       "<image width=\"1493\" height=\"1493\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAABdUAAAXVCAYAAADjLzZmAAAgAElEQVR4nOzasW0UaxiG0R1rM0Is\n",
       "QkixHOLQ1IBIqIAGKIAS3Ir7cOCUpQVLrmGXAix0n2Dmftd7z6ngnezXM9+y2+1OOwAAAAAA4B9d\n",
       "TA8AAAAAAIDXQlQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACAaD89AIB1/fjxY3rC6r5//z49YRPX\n",
       "19fTEwDghTdv3kxP2MTHjx+nJ2zi8fFxegIA/O+4VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACAaNntdqfpEQCs5+npaXrC6t6+fTs9YRP7/X56\n",
       "AgC88OnTp+kJm3h4eJiesIlv375NT9jE/f399AQA+CuX6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "7acHALCud+/eTU9Y3fF4nJ4AALxyy7JMT9jE169fpyds4v7+fnoCAPyVS3UAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAA\n",
       "AACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIj20wMAWNfxeJyesLrT6TQ9YRNXV1fTEzZxOBymJwDAC+f6nri9vZ2esInLy8vpCat7fn6engDA\n",
       "SlyqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "JKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSq\n",
       "AwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEC0nx4AwLouLs7vf+nxeJyesInPnz9PT9jE4XCYngAA\n",
       "LyzLMj1hEx8+fJiesIn3799PT1jd8/Pz9AQAVnJ+5QUAAAAAADYiqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAA\n",
       "QCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "JKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQLSf\n",
       "HgDAuo7H4/SE1Z1Op+kJAMAr5z0BAKzFpToAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARPvpAQCsa1mW\n",
       "6QkAAP855/pGOtfvOkc3NzfTEzbx5cuX6Qmr+fnz5/QE4JVwqQ4AAAAAAJGoDgAAAAAAkagOAAAA\n",
       "AACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAA\n",
       "AJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA\n",
       "kagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACR\n",
       "qA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGo\n",
       "DgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagO\n",
       "AAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAAkagOAAAAAACRqA4A\n",
       "AAAAAJGoDgAAAAAAkagOAAAAAACRqA4AAAAAAJGoDgAAAAAA0X56AADrOp1O0xNWd47ftNvtdofD\n",
       "YXoCALxwdXU1PWET5/qe+P379/SETSzLMj1hdXd3d9MTNvHr16/pCQD/OpfqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAPxh135xo1rjOA7PSboD/kgsqYa6bgBH8UhM94BkDw2SDVDDAkgd\n",
       "CSNpsWiwRdFzLYabT3LP4e09fZ4VfCevmJlPfgAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEB6MHALCsaZpGTyA6PDwcPWEVFxcXoycA8B8cHx+PnrCKrf5G2urviU+fPo2e\n",
       "sLj9fj96wipev349egLAX+dSHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAi\n",
       "UR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJR\n",
       "HQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEd\n",
       "AAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0A\n",
       "AAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAA\n",
       "AAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAA\n",
       "AAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAA\n",
       "ACJRHQAAAAAAIlEdAAAAAAAiUR0AAAAAACJRHQAAAAAAIlEdAAAAAACig9EDAFjWPM+jJyxui58J\n",
       "gG05PDwcPWExW/osv/N74v/l8vJy9ITFPXv2bPSEVXz//n30BIC/zqU6AAAAAABEojoAAAAAAESi\n",
       "OgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6\n",
       "AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoA\n",
       "AAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAA\n",
       "AAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAA\n",
       "AABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAA\n",
       "AESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAA\n",
       "RKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABEojoAAAAAAESiOgAAAAAARKI6AAAAAABE\n",
       "ojoAAAAAAETTbrebR48AYDkfP34cPWFxx8fHoyesYpqm0RNW8ebNm9ETVnF+fj56AnfQycnJ6Amr\n",
       "ePHixegJi3v8+PHoCYvZ6vfTPG/zr+9W3+vp06ejJyxuv9+PngDAQlyqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSq\n",
       "AwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAA\n",
       "AEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAA\n",
       "QCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABA\n",
       "NO12u3n0CACW8+TJk9ETFvfhw4fRE1bx4MGD0RNWMc/b/GkxTdPoCYvZ4htt6X1+t8W32u22+V5b\n",
       "eqstvs9ut603+t3Xr19HT1jF0dHR6AmLu76+Hj0BgIW4VAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA6GD0AACW9fnz59ETFnd6ejp6wirOzs5G\n",
       "T1jFvXv3Rk9YxTRNoyfwL37+/Dl6wiouLy9HT1jFxcXF6AmLu7q6Gj1hMVv9ftqqb9++jZ6wiuvr\n",
       "69ETAOCPXKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAKFWzDcAABKkSURBVAAAQCSqAwAAAABAJKoDAAAAAEAk\n",
       "qgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSq\n",
       "AwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoD\n",
       "AAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMA\n",
       "AAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQCSqAwAA\n",
       "AABAJKoDAAAAAEAkqgMAAAAAQCSqAwAAAABAJKoDAAAAAEAkqgMAAAAAQDTtdrt59AgAuIsePXo0\n",
       "esIq7t+/P3oCd9D19fXoCau4uroaPYE76NevX6MnrGKet/nX9/T0dPSEVbx9+3b0BAD4I5fqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABBNu91uHj0CAACA2+Hs7Gz0hFW8evVq9IRV7Pf70RNWcXR0NHoC\n",
       "APyRS3UAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiA5GDwAAAOD2ODk5GT1hFfM8j56wivfv34+eAAB3\n",
       "jkt1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAA\n",
       "AACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAA\n",
       "AIhEdQAAAAAAiER1AAAAAACIDkYPAAAA4PZ4+PDh6AmruLm5GT1hFT9+/Bg9AQDuHJfqAAAAAAAQ\n",
       "ieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ\n",
       "6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInq\n",
       "AAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoA\n",
       "AAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAA\n",
       "AAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAA\n",
       "AAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAA\n",
       "ABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAAEInqAAAAAAAQieoAAAAAABCJ6gAAAAAA\n",
       "EInqAAAAAAAQieoAAAAAABAdjB4AAADA7XFzczN6wirmeR49YRVb/VwAcJu5VAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAA\n",
       "AIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA6GD0AAAAAG6P8/Pz\n",
       "0RNW8fz589ETVjFN0+gJAHDnuFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAA\n",
       "gEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACA\n",
       "SFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBI\n",
       "VAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhU\n",
       "BwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQH\n",
       "AAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcA\n",
       "AAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgEhUBwAA\n",
       "AACASFQHAAAAAIBIVAcAAAAAgEhUBwAAAACASFQHAAAAAIBIVAcAAAAAgOhg9AAAAABuj5cvX46e\n",
       "sIp3796NnrCKL1++jJ4AAHeOS3UAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAA\n",
       "iER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACI\n",
       "RHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhE\n",
       "dQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1\n",
       "AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUA\n",
       "AAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAA\n",
       "AAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIhEdQAAAAAAiER1AAAA\n",
       "AACIRHUAAAAAAIhEdQAAAAAAiER1AAAAAACIRHUAAAAAAIim3W43jx4BAAAAAAD/By7VAQAAAAAg\n",
       "EtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS1QEAAAAAIBLVAQAAAAAgEtUBAAAAACAS\n",
       "1QEAAAAAIBLVAQAAAAD+accOBAAAAAAE+VuvMEBhBJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLq\n",
       "AAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEA\n",
       "AAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAA\n",
       "AMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACA\n",
       "SaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNU\n",
       "BwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4A\n",
       "AAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAA\n",
       "AAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAA\n",
       "TFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJik\n",
       "OgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUA\n",
       "AAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAA\n",
       "AAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAA\n",
       "YJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk\n",
       "1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoD\n",
       "AAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAA\n",
       "AACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAmqQ4AAAAA\n",
       "AJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFIdAAAAAAAm\n",
       "qQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAAAAAATFId\n",
       "AAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAAAJikOgAA\n",
       "AAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAwSXUAAAAA\n",
       "AJikOgAAAAAATFIdAAAAAAAmqQ4AAAAAAJNUBwAAAACASaoDAAAAAMAk1QEAAAAAYJLqAAAAAAAw\n",
       "SXUAAAAAAJikOgAAAAAATAEnvur0nOxPrQAAAABJRU5ErkJggg==\n",
       "\" transform=\"translate(498, 21)\"/>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Gray.(reshape(x, (28, 28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Flux.OneHotVector:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = test_set[2][:, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1 CUDA.CuArray{Float32,2}:\n",
       "  -5.6191826\n",
       "  -5.4696956\n",
       "  -0.2712011\n",
       "  -0.6270556\n",
       " -13.297237\n",
       "  -7.0104823\n",
       " -14.633313\n",
       "  10.112224\n",
       "  -2.7695477\n",
       "  -1.6269535"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1 CUDA.CuArray{Float32,2}:\n",
       " 1.1420706f-8\n",
       " 1.4447801f-6\n",
       " 3.2483037f-8\n",
       " 1.1095613f-10\n",
       " 0.9999125\n",
       " 8.6779195f-8\n",
       " 3.5969442f-6\n",
       " 7.271503f-8\n",
       " 1.2942992f-7\n",
       " 8.217325f-5"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1 CUDA.CuArray{Float32,2}:\n",
       " 1.1420706f-8\n",
       " 1.4447801f-6\n",
       " 3.2483037f-8\n",
       " 1.1095613f-10\n",
       " 0.9999125\n",
       " 8.6779195f-8\n",
       " 3.5969442f-6\n",
       " 7.271503f-8\n",
       " 1.2942992f-7\n",
       " 8.217325f-5"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(best_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilabels[argmax(model(x)[:,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilabels[argmax(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
